{"question_id": 0, "image": "image_000000.jpg", "question": "From the perspective of the building with the text \"Camara Municipal\", in which direction is the road sign with the text \"Titan\" to the entrance of the building?", "options": "A. To the left \nB. To the right\nC. Front right\nD. Front left", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[86.0, 750.0, 919.0, 1249.0], [460.0, 1023.0, 499.0, 1070.0]]"}
{"question_id": 1, "image": "image_000001.jpg", "question": "From the pespective of man wearing a black jacket and yellow waterproof, in which direction is the dock utility box (a white box with blue accents) relative to the  man?", "options": "A. To the left and slightly behind \nB. To the right and slightly ahead \nC. To the left and slightly ahead \nD. To the right and slightly behind ", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[274.0, 1563.0, 367.0, 1997.0], [459.0, 1162.0, 606.0, 1516.0]]"}
{"question_id": 2, "image": "image_000002.jpg", "question": "Which part of the person dressed in traditional attire, including a white cap and a white long-sleeved shirt or tunic, is closest to the bunch of bananas arranged in a circular pattern on a woven basket?", "options": "A. Feet \nB. Waist \nC. Head \nD. Back ", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[552.0, 758.0, 781.0, 1496.0], [685.0, 1097.0, 987.0, 1166.0]]"}
{"question_id": 3, "image": "image_000003.jpg", "question": "Which object is closer to the camera, the yellow and blue flag, or the coniferous tree with a conical shape and dense green foliage?", "options": "A. The flag\nB. The tree\nC. The same\nD. I don't know", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1453.0, 1111.0, 1599.0, 1426.0], [822.0, 1189.0, 869.0, 1280.0]]"}
{"question_id": 4, "image": "image_000004.jpg", "question": "From the perspective of the runner wearing a pink vest with bib number 4366, who is positioned slightly to the left of the image, in which direction is the man _ located in the middle of the road and dressed in a white long-sleeved top and black slim-fit pants _ relative to him?", "options": "A. On his right and slighly ahead.\nB. On his right and slightly behind.\nC. On his left and slighly ahead.\nD. On his left and slightly behind.", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1177.0, 672.0, 1337.0, 1068.0], [811.0, 666.0, 912.0, 942.0]]"}
{"question_id": 5, "image": "image_000005.jpg", "question": "From the perspective of the third person riding an electric scooter from left to right, in which direction is the red compact SUV located?", "options": "A. Front right\nB. Front left\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[1094.0, 1020.0, 1169.0, 1057.0], [460.0, 1084.0, 492.0, 1117.0]]"}
{"question_id": 6, "image": "image_000006.jpg", "question": "From the perspective of the woman who is bending over, in which direction is the girl wearing an orange vest located?", "options": "A. On her left and slightly behind.\nB. On her right and slightly behind.\nC. On her left and slightly ahead.\nD. On her right and slightly ahead.", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1187.0, 530.0, 1595.0, 1251.0], [1034.0, 579.0, 1267.0, 1388.0]]"}
{"question_id": 7, "image": "image_000007.jpg", "question": "From the perspective of the girl on the left side of the image, wearing a white short-sleeved top and sunglasses, in which direction is the man wearing a black robe and a hat located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[843.0, 1370.0, 1048.0, 2139.0], [403.0, 1403.0, 533.0, 1666.0]]"}
{"question_id": 8, "image": "image_000008.jpg", "question": "From the perspective of the red car, in which direction is the man walking a dog on the left side of the image located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[231.0, 679.0, 278.0, 777.0], [554.0, 695.0, 626.0, 736.0]]"}
{"question_id": 9, "image": "image_000009.jpg", "question": "From the perspective of the person wearing a tight black short-sleeve top and long pants, in which direction is the individual wearing pink clothes and a white hat located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1869.0, 864.0, 1964.0, 1006.0], [1176.0, 1169.0, 1215.0, 1297.0]]"}
{"question_id": 10, "image": "image_000010.jpg", "question": "From the perspective of the woman wearing a light-colored coat and bending down, in which direction is the adult male walking and dressed in a blue top and brown pants located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1061.0, 572.0, 1517.0, 1182.0], [1553.0, 588.0, 1619.0, 769.0]]"}
{"question_id": 11, "image": "image_000011.jpg", "question": "From the perspective of the adult male wearing an orange windbreaker and beige trousers, in which direction is the coffee shop's menu located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 150.0, 606.0, 560.0], [1591.0, 708.0, 1710.0, 1083.0]]"}
{"question_id": 12, "image": "image_000012.jpg", "question": "From the perspective of the person in the center of the image, wearing a purple long-sleeve top and a dark-colored scarf, in which direction is the motorcycle located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[817.0, 1375.0, 939.0, 1625.0], [593.0, 1395.0, 673.0, 1480.0]]"}
{"question_id": 13, "image": "image_000013.jpg", "question": "From the perspective of the man holding a plastic bottle, in which direction is the kitchen scale located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[494.0, 239.0, 1179.0, 1333.0], [1812.0, 1008.0, 2249.0, 1181.0]]"}
{"question_id": 14, "image": "image_000014.jpg", "question": "From the perspective of runner number 1181, in which direction is runner number 134 located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[101.0, 550.0, 243.0, 944.0], [573.0, 503.0, 746.0, 824.0]]"}
{"question_id": 15, "image": "image_000015.jpg", "question": "From the perspective of the person in the center of the image wearing red clothes, in which direction is the black fan located?", "options": "A. On his left and slightly behind.\nB. On his right and slightly behind.\nC. On his left and slightly ahead.\nD. On his right and slightly ahead.", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1049.0, 700.0, 1184.0, 851.0], [1464.0, 784.0, 1536.0, 959.0]]"}
{"question_id": 16, "image": "image_000016.jpg", "question": "From the perspective of the man wearing a mask and a brown-and-white striped shirt, in which direction is the woman _ wearing a white long-sleeve top, dark brown trousers, and carrying a bag on her left shoulder _ located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[588.0, 1004.0, 656.0, 1127.0], [728.0, 882.0, 782.0, 1008.0]]"}
{"question_id": 17, "image": "image_000017.jpg", "question": "From the perspective of the person standing in the back row, holding a stack of DVDs and wearing a blue robe, in which direction is the orange balloon located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[666.0, 366.0, 1165.0, 886.0], [525.0, 215.0, 745.0, 739.0]]"}
{"question_id": 18, "image": "image_000018.jpg", "question": "From the perspective of the white car, in which direction is the starbucks located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1147.0, 356.0, 2262.0, 1002.0], [78.0, 963.0, 918.0, 1269.0]]"}
{"question_id": 19, "image": "image_000019.jpg", "question": "From the viewpoint of the construction worker positioned on the left side of the image _ wearing a safety helmet and high-visibility vest _ what is the relative position of the crane hook block?", "options": "A. Front left\nB. Front right\nC. Upper left\nD. Upper right", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[108.0, 699.0, 230.0, 908.0], [266.0, 200.0, 363.0, 344.0]]"}
{"question_id": 20, "image": "image_000020.jpg", "question": "From the viewpoint of the individual dressed in a light windbreaker, wearing a white helmet, and facing forward, what is the relative direction of the sign for \"__\u25bc_\"?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[884.0, 460.0, 1490.0, 741.0], [1509.0, 1048.0, 1559.0, 1249.0]]"}
{"question_id": 21, "image": "image_000021.jpg", "question": "From the viewpoint of the couple traveling on a motorcycle _ the male rider in front wearing a burgundy shirt and black helmet, and the female rider behind dressed in a blue short-sleeved top with a shoulder bag on her right _ what is the relative direction of the double-decker bus?", "options": "A. Front left\nB. Front right\nC. Left\nD. Right", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[918.0, 419.0, 1722.0, 1233.0], [843.0, 922.0, 899.0, 993.0], [837.0, 897.0, 876.0, 951.0], [862.0, 900.0, 893.0, 969.0]]"}
{"question_id": 22, "image": "image_000022.jpg", "question": "From the viewpoint of the female individual seated in a wheelchair _ dressed in a light-colored floral shirt and wearing a white hat _ what is the relative direction of the signboard displaying the word \"PROGRAMS\"?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[374.0, 375.0, 789.0, 1281.0], [2016.0, 355.0, 2247.0, 702.0]]"}
{"question_id": 23, "image": "image_000023.jpg", "question": "From the viewpoint of the individual wearing a blue helmet, what is the relative position or directional location of the person dressed in a uniform marked with \"STAFF\"?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1370.0, 778.0, 1430.0, 995.0], [1246.0, 758.0, 1307.0, 908.0]]"}
{"question_id": 24, "image": "image_000024.jpg", "question": "From the viewpoint of the individual striding forward on the far left side of the scene _ dressed in a dark blue coat with gray hair _ what is the relative direction of the waiter/waitress currently taking a customer's order, who is wearing a white upper garment and black trousers?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1374.0, 1290.0, 1452.0, 1490.0], [7.0, 1332.0, 51.0, 1402.0]]"}
{"question_id": 25, "image": "image_000025.jpg", "question": "From the viewpoint of the young boy positioned at the center of the scene _ wearing blue sandals and aiming a water gun ahead _ what is the relative position or directional location of the banner displaying \"VISA\" and \"_\u55c9_\"?", "options": "A. Left\nB. Right\nC. Ahead\nD. Behind", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1025.0, 750.0, 1325.0, 1286.0], [1633.0, 144.0, 2015.0, 250.0]]"}
{"question_id": 26, "image": "image_000026.jpg", "question": "From the viewpoint of the black SUV, what is the relative position or directional location of the signage displaying both the Starbucks logo and the text \"DRIVE THRU\"?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[235.0, 163.0, 517.0, 1082.0], [0.0, 946.0, 273.0, 1059.0]]"}
{"question_id": 27, "image": "image_000027.jpg", "question": "From the viewpoint of the male individual positioned at the center of the roadway _ carrying a backpack _ what is the relative direction of the dark blue bicycle?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[877.0, 1778.0, 1033.0, 1924.0], [481.0, 1643.0, 506.0, 1722.0]]"}
{"question_id": 28, "image": "image_000028.jpg", "question": "From the viewpoint of the female individual dressed in a red upper garment and wearing a brown headscarf, what is the relative position of the seated woman who is wearing a pink headscarf?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[474.0, 697.0, 955.0, 1497.0], [1401.0, 724.0, 1563.0, 1290.0]]"}
{"question_id": 29, "image": "image_000029.jpg", "question": "From the perspective of the person in the center of the image _ holding an umbrella, wearing a black long-sleeve top and light blue jeans _ in which direction is the individual in the middle of the road, who is not using an umbrella but covering themselves with a coat and is wearing a navy and white striped shirt?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1009.0, 812.0, 1088.0, 1055.0], [1342.0, 815.0, 1397.0, 916.0]]"}
{"question_id": 30, "image": "image_000030.jpg", "question": "From the perspective of the elderly man standing on the bridge _ positioned to the left of a cyan-colored umbrella and wearing a dark gray long-sleeve top _ in which direction is the pavilion located at the center of the bridge?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1094.0, 541.0, 1327.0, 703.0], [915.0, 717.0, 944.0, 810.0], [953.0, 694.0, 1019.0, 724.0]]"}
{"question_id": 31, "image": "image_000031.jpg", "question": "From the viewpoint of the individual wearing a red hat and positioning the right hand beside his/her ear, what is the relative direction of the fountain in the scene?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[610.0, 989.0, 828.0, 1272.0], [908.0, 1260.0, 956.0, 1380.0]]"}
{"question_id": 32, "image": "image_000032.jpg", "question": "From the viewpoint of the male individual wearing glasses, what is the relative position or directional location of the person with a red headscarf?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1609.0, 1243.0, 1792.0, 1499.0], [1978.0, 1312.0, 2145.0, 1499.0]]"}
{"question_id": 33, "image": "image_000033.jpg", "question": "From the perspective of the standing person wearing a red robe and a dark purple hat, in which direction is the other individual _ also wearing a red robe but seated on a wooden object _ located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[1315.0, 289.0, 1592.0, 778.0], [1550.0, 155.0, 1795.0, 523.0]]"}
{"question_id": 34, "image": "image_000034.jpg", "question": "From the perspective of the second cyclist from the left _ wearing a yellow-and-black helmet and matching top _ in which direction is the person dressed in a white shirt with a burgundy tie located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[341.0, 473.0, 601.0, 900.0], [72.0, 388.0, 193.0, 846.0]]"}
{"question_id": 35, "image": "image_000035.jpg", "question": "Looking from the front to the back of the silver sedan, in which direction is the pink sign marked \"25%\" located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 1509.0, 641.0, 1970.0], [836.0, 1551.0, 986.0, 1817.0]]"}
{"question_id": 36, "image": "image_000036.jpg", "question": "From the perspective of the person wearing a red hat, a white short-sleeve top, and black trousers, and carrying a black handbag in their left hand, in which direction is the sign marked '\u6498\u9908_' located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[921.0, 800.0, 1170.0, 873.0], [717.0, 1050.0, 819.0, 1219.0]]"}
{"question_id": 37, "image": "image_000037.jpg", "question": "From the viewpoint of the individual dressed in a headscarf and a pink long-sleeved garment, what is the relative position or directional location of the elderly person with white hair?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[939.0, 338.0, 1789.0, 1497.0], [853.0, 349.0, 1312.0, 1397.0]]"}
{"question_id": 38, "image": "image_000038.jpg", "question": "From the viewpoint of the traffic director positioned at the center of the scene _ wearing a green reflective garment _ what is the relative direction of the person who is holding a camera?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[758.0, 889.0, 855.0, 1209.0], [1038.0, 958.0, 1128.0, 1308.0]]"}
{"question_id": 39, "image": "image_000039.jpg", "question": "From the perspective of this man, what is the relative direction of silver pot he is holding?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[435.0, 110.0, 1679.0, 1240.0], [402.0, 484.0, 573.0, 721.0]]"}
{"question_id": 40, "image": "image_000040.jpg", "question": "From the perspective of the woman wearing a green vest and black shorts, in which direction is the man _ standing with his hands on his hips, wearing a black tank top and black sunglasses _ located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[824.0, 113.0, 1028.0, 737.0], [1805.0, 348.0, 1982.0, 693.0]]"}
{"question_id": 41, "image": "image_000041.jpg", "question": "From the perspective of the man wearing a white shirt standing on the road, what is the relative relationship of the pole?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[666.0, 282.0, 784.0, 697.0], [829.0, 0.0, 900.0, 666.0]]"}
{"question_id": 42, "image": "image_000042.jpg", "question": "From the perspective of the woman wearing a black coat and talking on the phone, in which direction is the bald man located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[353.0, 465.0, 690.0, 1296.0], [1726.0, 361.0, 2082.0, 1155.0]]"}
{"question_id": 43, "image": "image_000043.jpg", "question": "From the viewpoint of the athlete with bib number 81101, what is the relative directional position of the athlete bearing bib number 060263?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[780.0, 701.0, 920.0, 1287.0], [1474.0, 732.0, 1570.0, 1057.0]]"}
{"question_id": 44, "image": "image_000044.jpg", "question": "From the viewpoint of the gentleman positioned in the lower right corner of the scene _ with a slicked-back hairstyle _ what is the relative direction of the residental building featuring round-shaped windows?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 0.0, 472.0, 988.0], [1531.0, 953.0, 2199.0, 1497.0]]"}
{"question_id": 45, "image": "image_000045.jpg", "question": "From the perspective of the dancer standing on the floor, what is the relative position of the acrobat?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[986.0, 535.0, 1324.0, 1382.0], [1181.0, 551.0, 1594.0, 1408.0]]"}
{"question_id": 46, "image": "image_000046.jpg", "question": "From the perspective of the woman standing in a tight black-and-red swimsuit, in which direction is the caf\u77c7 labeled \"BARIGANTINA\" located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1947.0, 1140.0, 2512.0, 1345.0], [778.0, 1341.0, 806.0, 1445.0]]"}
{"question_id": 47, "image": "image_000047.jpg", "question": "From the viewpoint of the horse, in which direction is the person located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 1406.0, 639.0, 2249.0], [1175.0, 0.0, 1499.0, 1419.0]]"}
{"question_id": 48, "image": "image_000048.jpg", "question": "From the perspective of the sitting person, what is the relative direction of the green plant that is positioned to the left of the bricks within the scene?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[1193.0, 793.0, 1333.0, 937.0], [391.0, 898.0, 466.0, 1013.0]]"}
{"question_id": 49, "image": "image_000049.jpg", "question": "From the viewpoint of the child dressed in pink, what is the relative directional position of the other child, who is wearing a blue-and-white-patterned hat?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1087.0, 627.0, 1433.0, 1497.0], [1952.0, 765.0, 2106.0, 1188.0]]"}
{"question_id": 50, "image": "image_000050.jpg", "question": "From the viewpoint of the male child wearing a blue outfit, what is the relative spatial position of the individual standing beneath the blue shelter and clad in gray clothing?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1132.0, 894.0, 1339.0, 1100.0], [1066.0, 872.0, 1152.0, 1092.0]]"}
{"question_id": 51, "image": "image_000051.jpg", "question": "From the viewpoint of the upright-standing male coach positioned at the sideline, what is the relative directional position of the seated male coach?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[295.0, 684.0, 531.0, 1387.0], [59.0, 884.0, 343.0, 1387.0]]"}
{"question_id": 52, "image": "image_000052.jpg", "question": "From the viewpoint of the man on paddle board  dressed in light blue shorts, what is the relative directional location of the white vessel moored at the shoreline?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 647.0, 253.0, 819.0], [1186.0, 713.0, 1313.0, 908.0]]"}
{"question_id": 53, "image": "image_000053.jpg", "question": "From the viewpoint of the individual dressed in blue attire, what is the relative directional position of the person in red?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[953.0, 717.0, 1091.0, 982.0], [1549.0, 694.0, 1646.0, 897.0]]"}
{"question_id": 54, "image": "image_000054.jpg", "question": "From the viewpoint of the heavier-set male individual dressed in a floral shirt and black hat, who is carrying a handbag in his left hand, what is the relative directional location of the menu stand situated beside the aircraft?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[138.0, 815.0, 241.0, 1069.0], [1713.0, 914.0, 1794.0, 1063.0]]"}
{"question_id": 55, "image": "image_000055.jpg", "question": "From the viewpoint of the young female child, what is the relative directional position of the yellow plastic tub?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1072.0, 521.0, 1386.0, 1175.0], [611.0, 956.0, 852.0, 1077.0]]"}
{"question_id": 56, "image": "image_000056.jpg", "question": "Looking from the building towards the sea, in which direction is the yellow floating dock located relative to the red-and-white boat?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1436.0, 1073.0, 1536.0, 1124.0], [918.0, 1014.0, 973.0, 1058.0]]"}
{"question_id": 57, "image": "image_000057.jpg", "question": "From the viewpoint of the male figure positioned at the extreme left of the scene _ with a ring visible on one of his fingers _ what is the relative directional location of the banner?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1219.0, 0.0, 1915.0, 699.0], [0.0, 640.0, 341.0, 1278.0]]"}
{"question_id": 58, "image": "image_000058.jpg", "question": "From the viewpoint of the young male child pointing his left hand upward toward the sky, clothed in a red shirt and denim pants, what is the relative directional position of the man wearing a light-patterned shirt and jeans, who is engaged in photographing others?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1132.0, 733.0, 1208.0, 903.0], [937.0, 1030.0, 992.0, 1199.0]]"}
{"question_id": 59, "image": "image_000059.jpg", "question": "From the viewpoint of the individual adorned with a white lace head covering, what is the relative positional orientation of the person wearing a green headscarf?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 132.0, 1012.0, 1494.0], [920.0, 436.0, 1503.0, 1272.0]]"}
{"question_id": 60, "image": "image_000060.jpg", "question": "From the viewpoint of the male individual gripping a suitcase in his right hand, what is the relative directional position of the person dressed in white and carrying a black backpack?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[711.0, 971.0, 999.0, 1498.0], [1099.0, 983.0, 1188.0, 1199.0]]"}
{"question_id": 61, "image": "image_000061.jpg", "question": "From the viewpoint of the female figure adorned in a white head covering and black long garment, what is the relative directional position of the male individual wearing a white outfit paired with a black waistcoat?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1195.0, 1229.0, 1227.0, 1321.0], [1557.0, 1269.0, 1597.0, 1340.0]]"}
{"question_id": 62, "image": "image_000062.jpg", "question": "From the viewpoint of the store employee wrapped in a black scarf and dressed in a light gray long-sleeved garment, what is the relative directional position of the elderly female customer who is wearing blue clothing, has gray hair, and is trying on footwear?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 803.0, 97.0, 1214.0], [396.0, 725.0, 536.0, 917.0]]"}
{"question_id": 63, "image": "image_000063.jpg", "question": "From the viewpoint of the male individual dressed in a black insulated jacket, who is holding chopsticks in his right hand, what is the relative directional position of the female figure seated cross-legged and wearing a gray long-sleeved garment?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[767.0, 1438.0, 1065.0, 1834.0], [90.0, 1374.0, 315.0, 1717.0]]"}
{"question_id": 64, "image": "image_000064.jpg", "question": "From the viewpoint of the female figure adorned with a green floral wreath, what is the relative directional position of the two pillows placed one on top of the other?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[595.0, 478.0, 782.0, 1188.0], [847.0, 851.0, 1248.0, 1078.0]]"}
{"question_id": 65, "image": "image_000065.jpg", "question": "From the viewpoint of the person with a smaller body frame, what is the relative directional position of the sniper rifle situated on the table at the extreme left side of the scene?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[1487.0, 367.0, 2192.0, 1216.0], [0.0, 1055.0, 276.0, 1346.0]]"}
{"question_id": 66, "image": "image_000066.jpg", "question": "From the viewpoint of the individual positioned at the front, what is the relative directional location of the person dressed in a red top with black sleeves and patterned shorts?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[412.0, 159.0, 754.0, 1377.0], [1268.0, 562.0, 1339.0, 771.0]]"}
{"question_id": 67, "image": "image_000067.jpg", "question": "From the viewpoint of the person, in which relative direction is the bicycle located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[328.0, 1106.0, 833.0, 2132.0], [337.0, 1438.0, 715.0, 2191.0]]"}
{"question_id": 68, "image": "image_000068.jpg", "question": "From the viewpoint of the police officer, what is the relative directional position of the individual dressed in a dark red hat and a shirt with yellow-and-black stripes?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[2110.0, 387.0, 2310.0, 1258.0], [1560.0, 470.0, 1693.0, 845.0]]"}
{"question_id": 69, "image": "image_000069.jpg", "question": "From the viewpoint of the male individual dressed in loose-fitting dark attire, who is holding a beverage in his left hand, what is the relative directional position of the novelty trash can shaped like a clown?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[837.0, 1245.0, 899.0, 1413.0], [1292.0, 1137.0, 1336.0, 1295.0]]"}
{"question_id": 70, "image": "image_000070.jpg", "question": "From the viewpoint of the female individual wearing eyeglasses, a lengthy green scarf, and a reddish-purple garment _ while holding an object in her right hand _ what is the relative directional position of the ornamental vase with roses placed on the table?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[1025.0, 775.0, 1219.0, 1204.0], [1108.0, 1073.0, 1404.0, 1499.0]]"}
{"question_id": 71, "image": "image_000071.jpg", "question": "From the viewpoint of the individual wearing a yellow head covering, what is the relative directional position of the female figure dressed in light blue attire and wearing prominent head adornments?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[855.0, 52.0, 1841.0, 1496.0], [464.0, 18.0, 951.0, 1499.0]]"}
{"question_id": 72, "image": "image_000072.jpg", "question": "From the viewpoint of the individual dressed in a military-green overcoat who is currently in a bent posture, what is the relative directional position of the person wearing a dark blue coat and consuming food while in motion?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[386.0, 543.0, 1151.0, 1496.0], [95.0, 438.0, 245.0, 672.0]]"}
{"question_id": 73, "image": "image_000073.jpg", "question": "From the viewpoint of the car registered as CS274WL, what is the relative directional position of the structure featuring a yellow spire-topped tower?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[1840.0, 1091.0, 2077.0, 1325.0], [820.0, 317.0, 1095.0, 590.0]]"}
{"question_id": 74, "image": "image_000074.jpg", "question": "From the viewpoint of the male individual standing beside the bicycle _ dressed in brown leather shoes and holding a briefcase _ what is the relative spatial position of the bicycle with respect to him?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[408.0, 707.0, 532.0, 1055.0], [322.0, 865.0, 425.0, 1083.0]]"}
{"question_id": 75, "image": "image_000075.jpg", "question": "From the viewpoint of the canine, what is the relative directional position of the individual standing on the floating dock?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[812.0, 1028.0, 987.0, 1283.0], [725.0, 576.0, 760.0, 667.0]]"}
{"question_id": 76, "image": "image_000076.jpg", "question": "From the perspective of the little girl, in which relative direction is the sculpture located?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[858.0, 438.0, 1502.0, 974.0], [1050.0, 881.0, 1259.0, 1286.0]]"}
{"question_id": 77, "image": "image_000077.jpg", "question": "From the viewpoint of the female figure with long hair, attired in a black sleeveless dress, wearing sunglasses, and holding a beverage in her right hand, what is the relative directional position of the male individual wearing a white shirt, black scarf, sunglasses, and carrying a shoulder bag?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "B", "category": "Reasoning/Perspective Transform", "target_instances": "[[359.0, 953.0, 407.0, 1035.0], [410.0, 954.0, 449.0, 1015.0]]"}
{"question_id": 78, "image": "image_000078.jpg", "question": "From the viewpoint of the individual seated on the bench engaged in a phone call, what is the relative directional position of the walking person dressed in a light-toned shirt and black trousers, holding a briefcase in their left hand and speaking on the phone simultaneously?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[187.0, 1004.0, 385.0, 1210.0], [907.0, 1025.0, 938.0, 1116.0]]"}
{"question_id": 79, "image": "image_000079.jpg", "question": "From the viewpoint of the male individual who is bare-chested, what is the relative directional position of the female figure dressed in light purple attire?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[0.0, 0.0, 1497.0, 1598.0], [0.0, 845.0, 278.0, 1815.0]]"}
{"question_id": 80, "image": "image_000080.jpg", "question": "From the viewpoint of the female individual with long hair, who is currently looking down at her mobile phone while wearing a black upper garment and distressed denim pants, what is the relative directional position of the person wearing light-colored clothing and jeans, and carrying a black crossbody bag?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[49.0, 1703.0, 134.0, 1990.0], [1333.0, 1708.0, 1442.0, 1888.0]]"}
{"question_id": 81, "image": "image_000081.jpg", "question": "From the viewpoint of the individual positioned on the right side of the scene _ dressed in red and holding a hitting bat _ what is the relative directional location of the first person in the foreground wearing blue clothing, when counting from left to right?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "D", "category": "Reasoning/Perspective Transform", "target_instances": "[[254.0, 431.0, 584.0, 988.0], [1770.0, 201.0, 1876.0, 561.0]]"}
{"question_id": 82, "image": "image_000082.jpg", "question": "From the viewpoint of the rear passenger on the motorcycle _ dressed in light attire and embracing the front rider _ what is the relative directional position of the pedestrian walking on the sidewalk, who is wearing a black upper garment and light gray trousers?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "C", "category": "Reasoning/Perspective Transform", "target_instances": "[[1954.0, 663.0, 2091.0, 949.0], [504.0, 698.0, 545.0, 844.0]]"}
{"question_id": 83, "image": "image_000083.jpg", "question": "From the viewpoint of the individual positioned on the right side of the scene _ who is of larger build and attired in a red form-fitting sleeveless top, white shorts, and white footwear accented with pink laces _ what is the relative directional position of the male figure standing upright while using a mobile device, wearing a black upper garment and gray shorts?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[3440.0, 1064.0, 3532.0, 1361.0], [3383.0, 1069.0, 3448.0, 1365.0]]"}
{"question_id": 84, "image": "image_000084.jpg", "question": "From the viewpoint of the individual gripping the light-blue rope, what is the relative directional position of the person holding the dark-blue rope?", "options": "A. Front left\nB. Front right\nC. Left rear\nD. Right rear", "answer": "A", "category": "Reasoning/Perspective Transform", "target_instances": "[[1507.0, 215.0, 1847.0, 1249.0], [1085.0, 260.0, 1371.0, 935.0]]"}
{"question_id": 85, "image": "image_000085.jpg", "question": "What are the first man on the right doing?", "options": "A. Looking at the camera\nB. Running\nC. Taking photos\nD. Drinking water", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1940.0, 858.0, 1993.0, 987.0]]"}
{"question_id": 86, "image": "image_000086.jpg", "question": "Counting from left to right, which table has a black handbag on it?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[206.0, 1152.0, 602.0, 1393.0], [238.0, 1106.0, 413.0, 1174.0]]"}
{"question_id": 87, "image": "image_000087.jpg", "question": "Counting from right to left, which person has a black watch on his/her left hand?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1647.0, 584.0, 1980.0, 1205.0]]"}
{"question_id": 88, "image": "image_000088.jpg", "question": "Starting from the long cardboard box where the girl is sitting, which cardboard box will begin to have words appear on the right side?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1149.0, 1104.0, 1597.0, 1499.0], [851.0, 1004.0, 1634.0, 1210.0]]"}
{"question_id": 89, "image": "image_000089.jpg", "question": "Which sculpture with a red base is the largest when counting from left to right?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. The fifth one\nF. The sixth one", "answer": "F", "category": "Reasoning/Ordering", "target_instances": "[[989.0, 1403.0, 1189.0, 1743.0]]"}
{"question_id": 90, "image": "image_000090.jpg", "question": "Which is the position (from right to left in the picture) of the gun barrel closest to the left of the gun barrel with the least rust?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[167.0, 536.0, 1671.0, 977.0]]"}
{"question_id": 91, "image": "image_000091.jpg", "question": "Which position is the person wearing a black and white floral shirt from left to right?", "options": "A.The third one\nB. The fourth one\nC. The fifth one\nD. The sixth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[138.0, 815.0, 241.0, 1069.0]]"}
{"question_id": 92, "image": "image_000092.jpg", "question": "From right to left, which numbered yellow boat with a door is the farthest to the right?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1914.0, 803.0, 2157.0, 884.0]]"}
{"question_id": 93, "image": "image_000093.jpg", "question": "To the left of the first house on the right, which utility pole (counting from left to right) is closest to the camera?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1412.0, 607.0, 1431.0, 896.0]]"}
{"question_id": 94, "image": "image_000094.jpg", "question": "What color is the gun barrel with the maximum angle of inclination?", "options": "A. Yellow\nB. Pink\nC. Green\nD. Black", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1387.0, 691.0, 1727.0, 1392.0]]"}
{"question_id": 95, "image": "image_000095.jpg", "question": "Among the trees behind the pink sign, which one is the shortest when counted from left to right?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[1012.0, 683.0, 1045.0, 922.0]]"}
{"question_id": 96, "image": "image_000096.jpg", "question": "Among the signs with text, which one (counting from left to right) has the most text?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\n", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1330.0, 1102.0, 1457.0, 1195.0]]"}
{"question_id": 97, "image": "image_000097.jpg", "question": "What color is the basket of the second bicycle from right to left?", "options": "A. White\nB. Black\nC. Blue\nD. Pink", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1382.0, 457.0, 1412.0, 497.0]]"}
{"question_id": 98, "image": "image_000098.jpg", "question": "What color is the second bicycle from right to left?", "options": "A. Black\nB. Black and green\nC. Black and orange\nD. Black and red", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[839.0, 556.0, 1192.0, 860.0]]"}
{"question_id": 99, "image": "image_000099.jpg", "question": "Counting from right to left, which position is the male wearing black pants sitting on a chair?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. The fifth one", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[1761.0, 126.0, 2102.0, 529.0]]"}
{"question_id": 100, "image": "image_000100.jpg", "question": "From top to bottom, which numbered rope is securing the man's safety?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[0.0, 819.0, 364.0, 905.0]]"}
{"question_id": 101, "image": "image_000101.jpg", "question": "Which position is the white object closely attached to the wall with the vent from right to left?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1554.0, 918.0, 1964.0, 1497.0]]"}
{"question_id": 102, "image": "image_000102.jpg", "question": "From right to left, which is the closest streetlight to the camera among those on the left side of the road?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. The fifth one", "answer": "E", "category": "Reasoning/Ordering", "target_instances": "[[253.0, 632.0, 368.0, 1232.0]]"}
{"question_id": 103, "image": "image_000103.jpg", "question": "What color is the third car after the orange car's rear end on the far right?", "options": "A. red\nB. white\nC. pink\nD. red", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[564.0, 416.0, 677.0, 512.0]]"}
{"question_id": 104, "image": "image_000104.jpg", "question": "Which soldier from right to left is holding a flag in his hand?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1206.0, 647.0, 1531.0, 1498.0]]"}
{"question_id": 105, "image": "image_000105.jpg", "question": "From left to right, what color is the third cloth hung on the railing?", "options": "A. Purple\nB. White\nC. Light green\nD. Blue with white patterns", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1138.0, 1103.0, 1179.0, 1211.0]]"}
{"question_id": 106, "image": "image_000106.jpg", "question": "From right to left, which number of the person wearing a bamboo hat is the farthest from the camera?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[861.0, 393.0, 1034.0, 559.0]]"}
{"question_id": 107, "image": "image_000107.jpg", "question": "From right to left, which number of the person is wearing a necklace and is a portrait on the poster?", "options": "A. The first\nB. The second\nC. The third\nD. None", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[174.0, 642.0, 683.0, 1520.0]]"}
{"question_id": 108, "image": "image_000108.jpg", "question": "Among the people standing in front of the white car, which one from left to right is leading the youngest child?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[0.0, 477.0, 528.0, 1497.0]]"}
{"question_id": 109, "image": "image_000109.jpg", "question": "In the lower half of the image, which is the smallest boat from right to left?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1421.0, 994.0, 1530.0, 1121.0]]"}
{"question_id": 110, "image": "image_000110.jpg", "question": "According to the position of the wooden sticks in the image, which sign from left to right is the closest to the camera?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[565.0, 161.0, 756.0, 749.0]]"}
{"question_id": 111, "image": "image_000111.jpg", "question": "Among the chairs on the left side of the sign, which one from left to right is closest to the right side of the person?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1002.0, 448.0, 1117.0, 587.0]]"}
{"question_id": 112, "image": "image_000112.jpg", "question": "Which pole from left to right has a light?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[986.0, 1424.0, 1166.0, 1542.0]]"}
{"question_id": 113, "image": "image_000113.jpg", "question": "From left to right, which number of person is carrying a crossbody bag with white patterns?", "options": "A. The second\nB. The third\nC. The fourth\nD. The fifth", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[524.0, 885.0, 841.0, 1499.0]]"}
{"question_id": 114, "image": "image_000114.jpg", "question": "From right to left, which bamboo is the closest to the camera?", "options": "A. The first\nB. The second\nC. The third\nD. None of the above", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1985.0, 667.0, 2033.0, 1499.0]]"}
{"question_id": 115, "image": "image_000115.jpg", "question": "Among the people who can be directly seen, which one from right to left is at the topmost position of the elevator?", "options": "A. The first\nB. The second\nC. The third\nD. None of the above", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1798.0, 1217.0, 1891.0, 1290.0]]"}
{"question_id": 116, "image": "image_000116.jpg", "question": "From left to right, which is the lowest-flying bird?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth\nE. The fifth\nF. The sixth", "answer": "F", "category": "Reasoning/Ordering", "target_instances": "[[1224.0, 1585.0, 1300.0, 1617.0]]"}
{"question_id": 117, "image": "image_000117.jpg", "question": "From right to left, which flower pot on the first floor is closest to the sculpture?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1056.0, 1858.0, 1092.0, 1895.0]]"}
{"question_id": 118, "image": "image_000118.jpg", "question": "Does the left road sign or the right road sign indicate where to reach after turning right?", "options": "A. Left\nB. Right", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[243.0, 0.0, 832.0, 241.0]]"}
{"question_id": 119, "image": "image_000119.jpg", "question": "From left to right, which number of person is the closest to the left and not holding straw?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth\nE. The fifth\nF. The sixth", "answer": "F", "category": "Reasoning/Ordering", "target_instances": "[[1661.0, 836.0, 1886.0, 1092.0]]"}
{"question_id": 120, "image": "image_000120.jpg", "question": "From right to left, which number of the person wearing a hat is carrying a schoolbag?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1625.0, 1000.0, 1742.0, 1388.0]]"}
{"question_id": 121, "image": "image_000121.jpg", "question": "From right to left, which number of person looks the oldest?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1737.0, 814.0, 2064.0, 1498.0]]"}
{"question_id": 122, "image": "image_000122.jpg", "question": "Among the deck chairs on the right, which one from near to far has a towel draped over it?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1077.0, 1613.0, 1281.0, 1761.0]]"}
{"question_id": 123, "image": "image_000123.jpg", "question": "From right to left, which number of the harp  does not have vertical stripes?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[943.0, 1106.0, 1274.0, 1843.0]]"}
{"question_id": 124, "image": "image_000124.jpg", "question": "From left to right, which number of the concrete pipes is placed vertically?", "options": "A. The first\nB. The second\nC. The third\nD. None", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1880.0, 1081.0, 2057.0, 1166.0]]"}
{"question_id": 125, "image": "image_000125.jpg", "question": "From left to right, which chair is surrounded by more vegetables?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[599.0, 1313.0, 1141.0, 2032.0]]"}
{"question_id": 126, "image": "image_000126.jpg", "question": "From left to right, which person is carrying the largest schoolbag?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "D", "category": "Reasoning/Ordering", "target_instances": "[[466.0, 1666.0, 524.0, 1830.0]]"}
{"question_id": 127, "image": "image_000127.jpg", "question": "From left to right, which door has a green object beside it?", "options": "A. The first\nB. The second\nC. The third\nD. The fourth", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[926.0, 928.0, 1002.0, 1101.0]]"}
{"question_id": 128, "image": "image_000128.jpg", "question": "In the drawing of the Earth on the sign held above the head, which is the nth Earth from left to right that does not have green?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. The fifth one", "answer": "E", "category": "Reasoning/Ordering", "target_instances": "[[1703.0, 154.0, 2087.0, 486.0]]"}
{"question_id": 129, "image": "image_000129.jpg", "question": "From left to right, which is the first ship without a cockpit?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1180.0, 981.0, 1338.0, 1047.0]]"}
{"question_id": 130, "image": "image_000130.jpg", "question": "From near to far, which vehicle is followed by a white car?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[0.0, 882.0, 75.0, 976.0]]"}
{"question_id": 131, "image": "image_000131.jpg", "question": "From right to left, which is the nth diamond-shaped chandelier that is adjacent to a purple diamond-shaped chandelier on the left and two yellow diamond-shaped chandeliers on the right?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. The fifth one\nF. The sixth one\nG. The seventh one\nH. The eighth one\nI. The ninth one\nJ. The tenth one\nK. None of the above", "answer": "F", "category": "Reasoning/Ordering", "target_instances": "[[1052.0, 1066.0, 1081.0, 1197.0]]"}
{"question_id": 132, "image": "image_000132.jpg", "question": "Among the vehicles on the left side of the yellow line, counting from near to far, which vehicle is closest to the silver car on the right side of the road?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[840.0, 933.0, 927.0, 996.0]]"}
{"question_id": 133, "image": "image_000133.jpg", "question": "From right to left, which is the second closest streetlight to us?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one\nE. None of the above", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[1453.0, 844.0, 1532.0, 1073.0]]"}
{"question_id": 134, "image": "image_000134.jpg", "question": "From right to left, which motorcycle is farther from the camera?", "options": "A. The first one\nB. The second one\nC. The third one\nD. No motorcycle", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1106.0, 607.0, 1499.0, 1169.0]]"}
{"question_id": 135, "image": "image_000135.jpg", "question": "From right to left, which is the first flag on the left side of the streetlight?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[2096.0, 1023.0, 2111.0, 1180.0]]"}
{"question_id": 136, "image": "image_000136.jpg", "question": "From right to left, what color is the first plastic bag held in someone's hand?", "options": "A. Red\nB. Yellow\nC. White\nD. Blue", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1857.0, 715.0, 1987.0, 934.0]]"}
{"question_id": 137, "image": "image_000137.jpg", "question": "From right to left, which is the nth person wearing a grass skirt who is holding a conch?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[2203.0, 539.0, 2598.0, 1333.0]]"}
{"question_id": 138, "image": "image_000138.jpg", "question": "From right to left, which transmission tower is the tallest?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1614.0, 405.0, 1743.0, 626.0]]"}
{"question_id": 139, "image": "image_000139.jpg", "question": "Counting from left to right, which man is not a senior officer wearing a formal military uniform with a golden braided rope tied around his chest?", "options": "A. The first one\nB. The second One\nC. The third one\nD. The fourth one", "answer": "C", "category": "Reasoning/Ordering", "target_instances": "[[33.0, 181.0, 333.0, 1164.0], [392.0, 269.0, 604.0, 1087.0], [634.0, 308.0, 837.0, 1037.0]]"}
{"question_id": 140, "image": "image_000140.jpg", "question": "In the center row of church pew, which row has the blue coil?", "options": "A. The first row from top to bottom\nB. The last row from top to bottom\nC. The second row from top to bottom\nD. The second to last row from top to bottom", "answer": "B", "category": "Reasoning/Ordering", "target_instances": "[[1262.0, 1331.0, 2140.0, 1499.0]]"}
{"question_id": 141, "image": "image_000141.jpg", "question": "Counting from right to left, which elephant did not enter the river?", "options": "A. The first one\nB. The second one\nC. The third one\nD. The fourth one", "answer": "A", "category": "Reasoning/Ordering", "target_instances": "[[1842.0, 706.0, 2125.0, 1138.0]]"}
{"question_id": 142, "image": "image_000142.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The front section of the ferry\nB. The middle section of the ferry \nC. The rear section of the ferry \nD. No part of the ferry is occluded by the structure ", "answer": "D", "category": "Perception/OCR", "target_instances": "[[1379.0, 893.0, 2000.0, 1086.0], [1147.0, 1050.0, 1691.0, 1203.0], [50.0, 50.0, 2184.953125, 266.0]]"}
{"question_id": 143, "image": "image_000143.jpg", "question": "Considering the soccer player in the red and white jersey with red accents (number 22) in the foreground, is his left foot occluded with the soccer ball?", "options": "A. Yes, they are in direct contact\nB. No, they are separated by a gap \nC. Only the closer stand is visible, so it cannot be determined \nD. They partially overlap ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[831.0, 375.0, 1228.0, 1154.0], [884.0, 1041.0, 979.0, 1136.0]]"}
{"question_id": 144, "image": "image_000144.jpg", "question": "In the image, which object is partially occluded by the handcart used for transporting goods?", "options": "A. The man riding a motorcycle\nB. The motorcycle being ridden\nC. The green auto-rickshaw\nD. The white van parked on the side of the street", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[511.0, 975.0, 727.0, 1278.0], [575.0, 960.0, 1004.0, 1280.0]]"}
{"question_id": 145, "image": "image_000145.jpg", "question": "Based on the image, which part of the motorcycle parked on the side of the street near a small with \"DB 2776 LU\" in text is occluded by the person standing in a street scene, wearing a horizontally striped shirt with alternating dark and light colors, possibly navy blue and white, facing away from the camera?", "options": "A. The front wheel of the motorcycle.\nB. The rear wheel of the motorcycle.\nC. The seat area of the motorcycle.\nD. The handlebars of the motorcycle.\nE. None of above.", "answer": "E", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[608.0, 731.0, 856.0, 1187.0], [861.0, 668.0, 1106.0, 966.0]]"}
{"question_id": 146, "image": "image_000146.jpg", "question": "What kind of occlusion relationship exists between the woman in the central picture wearing traditional green clothing and the woman wearing a peacock cloak behind her?", "options": "A. Completely blocked \nB. Partially blocked \nC. Completely unblocked\nD. Overlapping but visible", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[530.0, 139.0, 1032.0, 829.0], [297.0, 289.0, 611.0, 796.0]]"}
{"question_id": 147, "image": "image_000147.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The blue utility pole is attached to and physically touches the ski lift chair.\nB. The blue utility pole passes in front of the ski lift chair but does not make contact with it.\nC. The blue utility pole runs behind the ski lift chair and is only partially visible.\nD. The ski lift chair entirely blocks the blue utility pole so no part of it can be seen at that point.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[1125.0, 1848.0, 1293.0, 2263.0], [1268.0, 1934.0, 1319.0, 2069.0], [50.0, 50.0, 1435.921875, 374.0]]"}
{"question_id": 148, "image": "image_000148.jpg", "question": "What is the shading relationship between the black car on the road in the background and the roof of the leftmost house among the three houses placed side by side?", "options": "A. The roof and the car had no contact at all\nB. The roof covered the front half of the car\nC. The roof covered the rear half of the car\nD. The roof covered the lower half of the car\nE. The car was in front of the roof", "answer": "D", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[685.0, 717.0, 1315.0, 982.0], [924.0, 699.0, 1014.0, 723.0]]"}
{"question_id": 149, "image": "image_000149.jpg", "question": "In the center of the picture, there is a white cloth on which many vegetables are placed. Among them, there is a lettuce. What object is being obscured by it?", "options": "A. Potatoes\nB. Onion\nC. Eggplant \nD. Tomato", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1527.0, 1146.0, 1614.0, 1175.0], [1480.0, 1165.0, 1532.0, 1198.0]]"}
{"question_id": 150, "image": "image_000150.jpg", "question": "There is a set of knots under the sail in the picture, and there is a boatman beside them. What is the occluding relationship between them?", "options": "A. The rope is coiled around the boatman's hand.\nB. The rope does not occlude the boatman at all.\nC. The rope is blocking the front of the boatman.\nD. The boatman is occluding the rope.", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[624.0, 780.0, 832.0, 1278.0], [544.0, 778.0, 1009.0, 858.0]]"}
{"question_id": 151, "image": "image_000151.jpg", "question": "Part of the slender golden pin that lies diagonally beneath the square brass belt buckle is hidden from view. Which portion of the pin is occluded by the buckle? ", "options": "A. The pointed tip only is hidden, while the head remains visible. \nB. The central segment is hidden, leaving both the pointed tip and the head visible. \nC. The head end alone is hidden, while the pointed tip is fully visible. \nD. The pin is completely visible; no part of it is hidden at all. ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[627.0, 400.0, 842.0, 560.0], [549.0, 365.0, 964.0, 609.0]]"}
{"question_id": 152, "image": "image_000152.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Both the man and the woman are occluded by the railing.\nB. The woman occludes the man.\nC. The man occludes the woman.\nD. The man and the woman occlude the railing.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 1536.0, 296.0, 1855.0], [229.0, 1431.0, 296.0, 1551.0], [88.0, 1450.0, 154.0, 1541.0], [50.0, 50.0, 1382.953125, 266.0]]"}
{"question_id": 153, "image": "image_000153.jpg", "question": "Focus on the large blue plastic barrel that stands to the right of the doorway with posters, and the small cream-colored plastic stool placed slightly in front of the barrel. Are the barrel and the stool actually touching each other? ", "options": "A. Yes, the barrel is leaning against the stool \nB. No, there is a visible gap between them \nC. They touch only at the top edge \nD. They are stacked one on top of the other ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1503.0, 1008.0, 1630.0, 1267.0], [1314.0, 1179.0, 1422.0, 1314.0]]"}
{"question_id": 154, "image": "image_000154.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yes, his fingertips are touching the red bumper cover. \nB. No, there is a visible air gap between his fingertips and the bumper. \nC. His fingertips are only touching the underlying metal car frame, not the bumper. \nD. His fingertips are resting on a separate black rubber strip, not on the bumper. ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1590.0, 183.0, 2005.0, 1497.0], [57.0, 48.0, 465.0, 1497.0], [50.0, 50.0, 1986.953125, 302.0]]"}
{"question_id": 155, "image": "image_000155.jpg", "question": "Look at the curved red vertical trim panel closest to the right side, on the right wall, just beneath the luggage rack. Does this red trim panel make physical contact with the white underside of the overhead luggage shelf above it?", "options": "A. Yes, the red trim panel and the white shelf are in direct contact \nB. No, a visible gap separates the red trim panel and the white shelf \nC. They visually overlap but belong to different sides of the carriage, so contact cannot be determined \nD. The shelf is positioned entirely behind the red trim panel without touching it ", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1882.0, 377.0, 2187.0, 836.0], [1427.0, 317.0, 1860.0, 420.0]]"}
{"question_id": 156, "image": "image_000156.jpg", "question": "Are the black shoes on the ground at the lower right corner in contact with the white slippers beside them? ", "options": "A. There is no contact at all. \nB. One of the white slippers has touched the black shoes. \nC. Both the black shoes and the white shoes have touched each other. \nD. The black shoes are pressing on the red shoes.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1634.0, 1320.0, 1868.0, 1414.0], [1778.0, 1392.0, 1882.0, 1427.0]]"}
{"question_id": 157, "image": "image_000157.jpg", "question": "What is the relationship of obstruction between the silver car in the center of the picture and the girl wearing a black dress? ", "options": "A. There is no obstruction relationship between the two. \nB. The girl is blocking the car. \nC. The car is blocking the girl. \nD. The two are completely overlapping.", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1136.0, 1106.0, 1296.0, 1237.0], [1197.0, 1099.0, 1286.0, 1290.0]]"}
{"question_id": 158, "image": "image_000158.jpg", "question": "In the very front row on the pavement, two clear plastic water bottles with green caps stand side-by-side just in front of a maroon cylindrical pail. Are those two bottles in direct physical contact with each other? ", "options": "A. No, there is a visible gap between them. \nB. They are stacked one inside the other. \nC. Yes, their side surfaces are touching. \nD. They are separated by the maroon pail. ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1124.0, 1250.0, 1254.0, 1498.0], [1036.0, 1110.0, 1167.0, 1277.0]]"}
{"question_id": 159, "image": "image_000159.jpg", "question": "What is the occlusion relationship between the lady with golden hair and white jeans in the lower left corner of the picture and the lady in pink pants? ", "options": "A. There is no substantive contact between the two. \nB. The lady in pink pants is blocking the lady in white jeans. \nC. The lady in white jeans is blocking the lady in pink pants. \nD. The two are completely blocking each other.", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[704.0, 1291.0, 742.0, 1404.0], [732.0, 1296.0, 773.0, 1401.0]]"}
{"question_id": 160, "image": "image_000160.jpg", "question": "What is the relationship of obstruction between the pink pipe at the top of the picture and the dial on the right? ", "options": "A. There is no actual contact between them. \nB. The two are in contact with each other. \nC. The pipe is blocking the dial. \nD. The dial is blocking the pipe.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1732.0, 1134.0, 1873.0, 1446.0], [1588.0, 386.0, 1733.0, 514.0]]"}
{"question_id": 161, "image": "image_000161.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. They have no contact. \nB. The brown water tank partially covers the blue trash can. \nC. The blue trash can covers the brown water tank. \nD. There is no covering relationship and they are very far apart.", "answer": "B", "category": "Perception/OCR", "target_instances": "[[1507.0, 1174.0, 1685.0, 1323.0], [1583.0, 1129.0, 1716.0, 1272.0], [50.0, 50.0, 1891.9375, 266.0]]"}
{"question_id": 162, "image": "image_000162.jpg", "question": "What is the relationship between the branches in the foreground of the picture and the white bird above? ", "options": "A. The bird's feet have a clear contact with the tree. \nB. The bird is flying above the branches and there is no contact. \nC. The bird is below the branches and there is no contact. \nD. The bird is below the branches but there is a contact.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1028.0, 1155.0, 1294.0, 1297.0], [1201.0, 1131.0, 1235.0, 1201.0]]"}
{"question_id": 163, "image": "image_000163.jpg", "question": "Regarding the orange plastic cup held out by the crouching barefoot man and the slim vertical grey pole rising from the pavement beside him, which statement best describes their contact relationship? ", "options": "A. The cup is resting directly against the pole. \nB. The cup and the pole are separated by a visible gap (they do not touch). \nC. The pole passes through an opening in the cup_\u4ea4_ rim. \nD. The cup is hanging from a string tied to the pole. ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1323.0, 224.0, 1362.0, 799.0], [901.0, 547.0, 1035.0, 685.0]]"}
{"question_id": 164, "image": "image_000164.jpg", "question": "Look at the upper-centre of the image where a grey-sleeved arm is holding a black DSLR camera in front of a person wearing a cream-coloured sweater. What is the relationship between this camera and the man wearing a black backpack and a white sweater over there? ", "options": "A. The camera doesn't cover any part of the man. \nB. The camera covers the man's head. \nC. The camera blocks the man's pants. \nD. There is a large distance between the camera and the man.", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[971.0, 36.0, 1304.0, 1286.0], [1102.0, 0.0, 1270.0, 92.0]]"}
{"question_id": 165, "image": "image_000165.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. No, there is a visible gap between his fingers and the metal bar \nB. Yes, his fingertips are touching the bar \nC. Only his knuckles are touching the bar \nD. His hand is gripping the top horizontal rail of the barricade ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[669.0, 639.0, 2221.0, 1496.0], [1121.0, 650.0, 1581.0, 1499.0], [50.0, 50.0, 2139.96875, 266.0]]"}
{"question_id": 166, "image": "image_000166.jpg", "question": "Looking at the bottom of the dark-metal irrigation sprinkler that has two small wheels and stands near the right-center of the frame, what is its visual relationship with the rows of young green maize plants closest to the camera?", "options": "A. The maize plants overlap the sprinkler, hiding the lowest part of its legs and wheels. \nB. The maize plants are entirely behind the sprinkler, so every part of the sprinkler's legs and wheels is unobstructed. \nC. The sprinkler completely blocks the view of the maize plants immediately in front of it. \nD. There is a clear horizontal strip of bare soil separating the sprinkler_\u4ea4_ legs from the nearest maize plants, so they do not overlap. ", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[0.0, 852.0, 2249.0, 1495.0], [1558.0, 855.0, 1666.0, 974.0]]"}
{"question_id": 167, "image": "image_000167.jpg", "question": "On the left side of the picture, there is a car and a man walking in a brown jacket. What kind of relationship is there between them? ", "options": "A. The man is in the car. \nB. The man is in front of the car and blocks part of the car body. \nC. The man is behind the car and blocks part of the car body. \nD. The man has no direct contact with the car.", "answer": "D", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[413.0, 1054.0, 503.0, 1304.0], [181.0, 1085.0, 318.0, 1168.0]]"}
{"question_id": 168, "image": "image_000168.jpg", "question": "A central portion of the distant bluish mountain range in the background is not visible because another object blocks it. Which object is doing the occluding? ", "options": "A. The triangular, tile-covered roof of the rough-stone house that has a single chimney \nB. The leafy green tree on the extreme right edge of the frame \nC. The overhanging branch with green leaves entering from the top left corner \nD. No object is blocking the mountains; the ridge is entirely visible ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[960.0, 670.0, 1681.0, 1286.0], [1839.0, 778.0, 2255.0, 1496.0], [788.0, 549.0, 1978.0, 910.0], [0.0, 0.0, 347.0, 352.0]]"}
{"question_id": 169, "image": "image_000169.jpg", "question": "In the upper-right desert scene, a woman dressed in light-green silk kneels with her palms pressed together while a man in a brown robe lies face-down on the sand in front of her. What is the actual contact state between these two figures? ", "options": "A. Her fingertips are touching the back of his head. \nB. Her left knee is touching his right elbow. \nC. The hem of her tunic is touching his ankle. \nD. No part of her body or clothing is touching him. ", "answer": "D", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1030.0, 154.0, 1186.0, 417.0], [1177.0, 260.0, 1475.0, 479.0]]"}
{"question_id": 170, "image": "image_000170.jpg", "question": "Regarding the man wearing light-beige trousers, white sandals, and a brown backpack who is walking in front of the silver hatchback parked at the curb, what is his contact relationship with the car? ", "options": "A. He is leaning against the car's hood with both hands. \nB. One of his feet is touching the car's front bumper. \nC. There is no physical contact; a visible gap separates him from the car. \nD. His right leg is pressed against the car's left front fender.", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1133.0, 963.0, 1596.0, 1182.0], [1132.0, 894.0, 1286.0, 1273.0]]"}
{"question_id": 171, "image": "image_000171.jpg", "question": "What is the occlusion relationship between the building with the number \"26\" on the right side of the picture and the adjacent building? ", "options": "A. Building 26 is obscured by the building on the left. \nB. The two buildings are not adjacent. \nC. Building 26 obscures the building on the left. \nD. The two buildings are not in contact at all.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1202.0, 1051.0, 1335.0, 1328.0], [1272.0, 923.0, 1383.0, 1269.0]]"}
{"question_id": 172, "image": "image_000172.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Speak green menu board Black ceiling panel \nB. green menu board Speaker Black ceiling panel \nC. Black ceiling panel Speaker green menu board \nD. green menu board Black ceiling panel Speaker ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1009.0, 182.0, 1930.0, 587.0], [1007.0, 354.0, 1259.0, 745.0], [969.0, 380.0, 1056.0, 510.0], [50.0, 50.0, 1993.90625, 338.0]]"}
{"question_id": 173, "image": "image_000173.jpg", "question": "The slender dark-green church spire on the far right is partly hidden by the cream-colored building that has vertical dark window columns beneath it. Which specific section of the spire is being occluded by that building? ", "options": "A. Only the very tip of the spire \nB. The mid-section that sits just above the building's roofline \nC. The base of the spire where it meets the main roof of the church tower \nD. No part of the spire is occluded; the entire spire is visible ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1544.0, 558.0, 2021.0, 1159.0], [2015.0, 845.0, 2179.0, 1151.0]]"}
{"question_id": 174, "image": "image_000174.jpg", "question": "A curved stainless-steel safety rail runs horizontally across the lower part of the image in front of a row of clear Erlenmeyer flasks. Which specific region of the flask that is furthest left is hidden from view by this metal rail? ", "options": "A. The very top rim of the flask \nB. The lower half of the flask's conical body, near its base \nC. No part of the flask is hidden; the rail is positioned entirely below it \nD. Only the narrow neck of the flask just below the rim ", "answer": "D", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[58.0, 1247.0, 943.0, 1498.0], [323.0, 1085.0, 588.0, 1498.0]]"}
{"question_id": 175, "image": "image_000175.jpg", "question": "At the moment captured in the photo, are the two children (the one in a camouflage outfit and the one in a light-blue T-shirt) physically touching each other? \n ", "options": "A. Yes, they are holding hands \nB. Yes, the camouflage boy's left elbow is resting on the other boy's shoulder \nC. No, there is a clear gap between them \nD. No, they are separated by the black guard-rail ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1772.0, 1006.0, 1923.0, 1379.0], [1550.0, 1030.0, 1649.0, 1353.0]]"}
{"question_id": 176, "image": "image_000176.jpg", "question": "In the lower right corner of the picture, there is a person and an advertisement board. Did they have any contact? ", "options": "A. The person covered the advertisement board. \nB. There was no mutual contact. \nC. The advertisement board covered the person. \nD. It is unclear about the relationship between these two.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1267.0, 1855.0, 1344.0, 2009.0], [1336.0, 1822.0, 1396.0, 2015.0]]"}
{"question_id": 177, "image": "image_000177.jpg", "question": "What kind of relationship exists between the person riding the electric bike at the far left of the image and the street lamp in the middle? ", "options": "A. There is no contact at all. \nB. The person covers the light of the lamp. \nC. The lamp covers the person. \nD. It cannot be determined.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[955.0, 193.0, 1132.0, 1058.0], [174.0, 1030.0, 213.0, 1074.0]]"}
{"question_id": 178, "image": "image_000178.jpg", "question": "The woman wearing a knee-length lime-green dress on the far left is standing near a dark wooden bench. What is the actual contact state between her body and that bench? ", "options": "A. Her back is leaning against the bench's backrest. \nB. Only her left elbow touches the bench. \nC. There is a clear gap; she is not touching the bench at all. \nD. Both of her calves are pressed against the seat edge. ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[186.0, 439.0, 374.0, 930.0], [0.0, 538.0, 187.0, 715.0]]"}
{"question_id": 179, "image": "image_000179.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The leftmost front leg of the chaise lounge \nB. The rightmost button-tufted backrest section near the window \nC. The seat-cushion area located directly behind the seated gentleman's back \nD. The entire armrest furthest from the viewer (near the window) ", "answer": "C", "category": "Perception/OCR", "target_instances": "[[779.0, 455.0, 1719.0, 1017.0], [890.0, 453.0, 1445.0, 1096.0], [50.0, 50.0, 2053.90625, 266.0]]"}
{"question_id": 180, "image": "image_000180.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The very top (roof) of the tower \nB. The left sloping wing of the tower near its upper half \nC. The large central arched opening \nD. The right base pillar at ground level ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[398.0, 781.0, 1471.0, 1499.0], [375.0, 463.0, 565.0, 1499.0], [50.0, 50.0, 1438.90625, 266.0]]"}
{"question_id": 181, "image": "image_000181.jpg", "question": "Which object partially hides the lower legs of the guard wearing a bright blue robe who is walking nearest to the viewer inside the arch? ", "options": "A. The black vertical information signboard standing on the stone floor in the center of the archway. \nB. A rectangular grey stone block lying on the ground to the right of the guard. \nC. The hem of the guard's own blue robe. \nD. The yellow flag with dragon patterns fluttering above the guard. ", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1221.0, 668.0, 1350.0, 996.0], [1281.0, 765.0, 1377.0, 1026.0]]"}
{"question_id": 182, "image": "image_000182.jpg", "question": "Look at the brown, sticker-covered pole running down the extreme right edge of the image. What is the actual contact state between the bottom end of this pole and the cobblestone alley? ", "options": "A. The pole clearly rests directly on the cobblestones, with no visible gap. \nB. The pole stops slightly above the cobblestones, leaving a narrow gap. \nC. The pole appears to be set into a recess in the cobblestones. \nD. The pole's lower end is entirely outside the frame, so its contact cannot be determined. ", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[12.0, 1059.0, 1405.0, 1999.0], [1324.0, 0.0, 1439.0, 1851.0]]"}
{"question_id": 183, "image": "image_000183.jpg", "question": "Regarding physical contact in the scene, what best describes the relationship between the right-hand edge of the RIVER OF LIFE signboard and the vertical black fence rod immediately beside it? ", "options": "A. They are in direct contact; the board is fastened to the rod. \nB. A visible gap separates the board and the rod. \nC. The rod passes in front of the sign without touching it. \nD. The sign sits completely behind the rod with no overlap. ", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[409.0, 262.0, 1873.0, 1259.0], [1859.0, 459.0, 1999.0, 503.0]]"}
{"question_id": 184, "image": "image_000184.jpg", "question": "What is the occlusion relationship between the backpack of the person on the far left in the picture and the person herself? ", "options": "A. The backpack covers the person. \nB. The person covers the backpack. \nC. The two do not come into contact with each other. \nD. It is impossible to determine.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[0.0, 450.0, 239.0, 1396.0], [0.0, 899.0, 155.0, 1082.0]]"}
{"question_id": 185, "image": "image_000185.jpg", "question": "Looking at the overlapping objects near the top-left of the image, which element is closest to the camera (i.e., lies on the foremost visual layer)? ", "options": "A. The brown canopy roof \nB. The sailboat masts rising into the sky \nC. The break-dancer_\u4ea4_ fully extended left leg and sneaker \nD. The blue sky itself ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[0.0, 0.0, 2264.0, 832.0], [0.0, 222.0, 939.0, 690.0], [155.0, 467.0, 1464.0, 1269.0], [313.0, 0.0, 342.0, 744.0]]"}
{"question_id": 186, "image": "image_000186.jpg", "question": "In the center of the scene a clear plastic bag containing fish hangs from a string. Which object is partially hidden behind this bag? \n ", "options": "A. A silver grilling rack lying flat on the counter \nB. The torso of the person wearing a bright red T-shirt \nC. A glowing bulb suspended from the stall frame \nD. The green Good & Drink banner at the very top ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[0.0, 0.0, 1999.0, 292.0], [593.0, 419.0, 800.0, 851.0], [831.0, 307.0, 1025.0, 654.0], [262.0, 282.0, 334.0, 396.0]]"}
{"question_id": 187, "image": "image_000187.jpg", "question": "Which part of the white, column-fronted building near the right edge of the scene is hidden behind the overhanging leafy tree in the upper right corner? ", "options": "A. Its ground-floor entrance door \nB. The lower half of its tall vertical red decorative stripe \nC. The entire left-hand side of its roof parapet \nD. The upper right-hand corner of its fa__de, including part of the cornice ", "answer": "D", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[1147.0, 0.0, 1499.0, 922.0], [1212.0, 763.0, 1361.0, 1049.0]]"}
{"question_id": 188, "image": "image_000188.jpg", "question": "Is there any contact or obstruction relationship between the railing on the far right of the picture and the towering power poles? ", "options": "A. The base of the railing is in contact with the power pole. \nB. The middle part of the railing is in contact with the power pole. \nC. There is no contact at all between the two. \nD. It cannot be determined.", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[2387.0, 521.0, 2666.0, 561.0], [2366.0, 0.0, 2396.0, 563.0]]"}
{"question_id": 189, "image": "image_000189.jpg", "question": "Is there any shading relationship between the curved white arch part of the pedestrian bicycle bridge and the silver domed music hall (Said Music Hall) on the opposite side?", "options": "A. Intersecting \nB. Completely unshaded \nC. Unclear \nD. Coinciding", "answer": "A", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[864.0, 609.0, 1153.0, 721.0], [1104.0, 542.0, 1659.0, 764.0]]"}
{"question_id": 190, "image": "image_000190.jpg", "question": "One of the silhouetted cargo ships lies almost directly under the bright sun's reflection on the water, yet the lower part of its hull is not visible. What is most likely occluding that lower portion? \n \n ", "options": "A. A person sitting on the right-hand bench \nB. The horizontal _\u4ea4_rm_ slab of the stone statue \nC. The dark line of shoreline rocks situated right at the water's edge \nD. The grassy lawn in the foreground ", "answer": "C", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[940.0, 1200.0, 1319.0, 1293.0], [1130.0, 1256.0, 1252.0, 1316.0], [1236.0, 1202.0, 1304.0, 1216.0]]"}
{"question_id": 191, "image": "image_000191.jpg", "question": "Regarding physical contact, which statement is correct about the mannequin displaying a white, knee-length tunic that stands between the blue-dress mannequin and the pedestrian walkway? ", "options": "A. The base of the white-tunic mannequin is in direct contact with a rectangular metal drainage grate. \nB. The white-tunic mannequin's stand is touching the tiled sidewalk but not touching the drainage grate. \nC. The white-tunic mannequin is leaning against the storefront wall. \nD. The white-tunic mannequin is directly touching the blue-dress mannequin's stand. ", "answer": "B", "category": "Reasoning/Contact and Occlusion", "target_instances": "[[714.0, 1476.0, 1038.0, 1686.0], [251.0, 1157.0, 326.0, 1415.0], [761.0, 1442.0, 889.0, 1497.0]]"}
{"question_id": 192, "image": "image_000192.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The price tag with \"200\" in text\nB. The price tag with \"300\" in text\nC. The price tag with \"500\" in text\nD. The price tag with \"800\" in text", "answer": "B", "category": "Perception/OCR", "target_instances": "[[957.0, 1115.0, 1293.0, 1449.0], [1053.0, 939.0, 1142.0, 1075.0], [50.0, 50.0, 2177.9375, 230.0]]"}
{"question_id": 193, "image": "image_000193.jpg", "question": "Which line is the person on the right in the photo walking on?", "options": "A. The pavement or the sidewalk\nB. The non-motorized vehicle lane\nC. The first motorway from left to right\nD. The second motorway from left to right", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[1688.0, 772.0, 1804.0, 1021.0]]"}
{"question_id": 194, "image": "image_000194.jpg", "question": "Which of the following objects is inside the building on the right?", "options": "A. The buddhist monk in orange on the right\nB. The person in blue on the right\nC. The couple in the middle of the image\nD. The black car in the middle", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[634.0, 404.0, 1499.0, 1429.0], [1117.0, 1357.0, 1177.0, 1418.0]]"}
{"question_id": 195, "image": "image_000195.jpg", "question": "Where are the four potted plants in the foreground?", "options": "A. The landscaped patch directly in front of the wall\nB. The grass in the foreground\nC. The garden bed behind the grass\nD. The landscaped patch on the right of the stairs", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[97.0, 1930.0, 1499.0, 2143.0], [515.0, 1569.0, 916.0, 1997.0], [62.0, 1447.0, 565.0, 1923.0], [1091.0, 1647.0, 1384.0, 2052.0], [917.0, 1782.0, 1091.0, 1965.0]]"}
{"question_id": 196, "image": "image_000196.jpg", "question": "The grass lawn surrounded by a low, beige-colored metal edging forms a contained green area. Which of the following objects is located inside that contained lawn space?", "options": "A. The dark evergreen tree positioned directly behind the white columns of the building \nB. The concrete sidewalk inside the sunken pedestrian channel \nC. The flowering shrub with bright pink blossoms standing on a small rock island \nD. The parked automobiles barely visible through foliage at the far left background ", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[906.0, 703.0, 1169.0, 1011.0]]"}
{"question_id": 197, "image": "image_000197.jpg", "question": "Where is the slim, grey street-lamp with a white rectangular luminaire (positioned just left of the teal pavilion) in relation to the dark-green metal fence?", "options": "A. Fully behind (inside) the fence, rooted in the garden area. \nB. Straddling the fence, with its base outside and pole inside. \nC. In front of the fence on the concrete sidewalk. \nD. Hanging from the fade of the nearest tower.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 1839.0, 1224.0, 2028.0], [92.0, 1587.0, 916.0, 1871.0], [692.0, 1604.0, 726.0, 1795.0]]"}
{"question_id": 198, "image": "image_000198.jpg", "question": "Where is the man in the red shirt and blue jeans positioned relative to the red box?", "options": "A. The man is standing to the left of the red box.\nB. The man is standing to the right of the red box.\nC. The man is standing upon red box.\nD. The man is standing below red box.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[828.0, 705.0, 919.0, 960.0], [897.0, 848.0, 960.0, 992.0]]"}
{"question_id": 199, "image": "image_000199.jpg", "question": "Is the collection of numerous golden-brown, irregularly shaped food items entirely contained within the enclosed glass display section of the teal and green wheeled food cart?", "options": "A. No, some of the food items are located on the exterior shelves of the cart.\nB. Yes, all visible food items are inside the glass display.\nC. No, the food items are only partially inside the display, with some protruding.\nD. The glass display is open, so they are not fully contained.", "answer": "B", "category": "Reasoning/Spatial Containment", "target_instances": "[[896.0, 355.0, 1052.0, 608.0]]"}
{"question_id": 200, "image": "image_000200.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. It is on the left to the sink.\nB. It is on the right to the sink.\nC. There is no toliet in the image.\nD. It is above the sink.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1033.0, 1094.0, 1411.0, 1499.0], [1598.0, 1043.0, 2120.0, 1267.0], [50.0, 50.0, 1069.984375, 230.0]]"}
{"question_id": 201, "image": "image_000201.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The open-air space beside the bright green wooden wall.\nB. The area directly under the small, rusty, corrugated metal roof with a jagged edge.\nC. The interior of the structure with the bright green wooden wall.\nD. The space upon the larger, dark red, corrugated metal roof to its upper left.", "answer": "B", "category": "Perception/OCR", "target_instances": "[[0.0, 211.0, 840.0, 1496.0], [408.0, 1304.0, 646.0, 1499.0], [50.0, 50.0, 2171.84375, 266.0]]"}
{"question_id": 202, "image": "image_000202.jpg", "question": "Is the clear plastic water bottle with the red-and-white label lying sideways in the turquoise bucket at the bottom-right of the image completely contained within that bucket? ", "options": "A. The bottle sits on the ground beside the bucket. \nB. Yes, the bottle is completely inside the bucket. \nC. No, part of the bottle projects above the rim of the bucket. \nD. There is no bottle around the bucket.", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[1584.0, 1085.0, 1897.0, 1398.0], [1718.0, 910.0, 1885.0, 1211.0]]"}
{"question_id": 203, "image": "image_000203.jpg", "question": "Is the golden ornament attached to the purple-robed statue on the float completely enclosed by the transparent plastic sheet? ", "options": "A. No, the ornament is entirely outside the sheet \nB. Yes, it is fully inside the sheet \nC. Only the lower part of the ornament is inside the sheet \nD. Only the upper part of the ornament is inside the sheet ", "answer": "B", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 0.0, 472.0, 988.0]]"}
{"question_id": 204, "image": "image_000204.jpg", "question": "Is the prominent yellow umbrella structure with \"NOK AIR\" branding and associated promotional displays located entirely within the operational area directly behind the physical barrier of the \"CHECK-IN COUNTERS\" desks and signage?", "options": "A. Yes, it is situated well within the delineated check-in operational zone.\nB. No, it is positioned in the general public concourse area, in front of the check-in counter structures.\nC. It straddles the boundary, with its base in the concourse and the top extending over the counters.\nD. It is located on the upper mezzanine level, overlooking the check-in area.", "answer": "B", "category": "Reasoning/Spatial Containment", "target_instances": "[[835.0, 627.0, 1093.0, 922.0], [1127.0, 644.0, 1682.0, 698.0]]"}
{"question_id": 205, "image": "image_000205.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A white-framed window with vertical bars \nB. A tall grey drainpipe running down the wall \nC. An angled rust-colored metal awning \nD. A wooden outbuilding with a dark roof in the background ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[2100.0, 976.0, 2248.0, 1059.0], [50.0, 50.0, 2185.953125, 266.0]]"}
{"question_id": 206, "image": "image_000206.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The right-hand vertical support pillar of the finish line gantry, which displays multiple sponsor logos.\nB. The underside of the main horizontal overhead beam.\nC. One of the orange traffic cones lining the track.\nD. The t-shirt of a race official standing near the finish line.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 2249.0, 1493.0], [50.0, 50.0, 2126.96875, 266.0]]"}
{"question_id": 207, "image": "image_000207.jpg", "question": "The bare feet of the monk in an orange robe, who is second from the left in the line of four monks and is holding a textured yellow-brown alms bowl while looking downwards, are positioned on which specific part of the depicted temple area?", "options": "A. On the grey, marble-like surface of the elevated temple steps.\nB. Inside the main prayer hall of the temple.\nC. On the red-tiled roof of the temple.\nD. On the ground-level pavement in front of the temple stairs.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 919.0, 1172.0, 1496.0], [227.0, 415.0, 522.0, 1118.0]]"}
{"question_id": 208, "image": "image_000208.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. On the light-colored rectangular performance mat.\nB. On the red and grey patterned paved area in front of the steps.\nC. On one of the wide concrete steps leading up to the building entrance.\nD. On the highest tier of the steps, near the building entrance.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[0.0, 657.0, 1499.0, 905.0], [308.0, 443.0, 480.0, 732.0], [50.0, 50.0, 1384.984375, 338.0]]"}
{"question_id": 209, "image": "image_000209.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The crane is above the car, lifting it.\nB. The crane is behind the car, pulling it.\nC. The crane is in front of the car, supporting it.\nD. The crane is to the left of the car, lifting it.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 1982.0, 1387.0], [50.0, 50.0, 1290.96875, 230.0]]"}
{"question_id": 210, "image": "image_000210.jpg", "question": "The main mass of white, fluffy fibers is predominantly situated on which surface?", "options": "A. The dark, textured surface of the rectangular wooden implement held in the woman's left hand.\nB. Spread across the woman's lap, beneath the wooden tools.\nC. Inside the orange and white striped bag visible in the upper background.\nD. The surface of the rectangular, smooth, light-brown wooden paddle held in the woman's left hand.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 0.0, 1672.0, 1496.0], [1368.0, 1256.0, 1867.0, 1499.0]]"}
{"question_id": 211, "image": "image_000211.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yes, the forward half is inside the reinforcing-bar cage, passing between the steel rods \nB. No, the entire drill bit remains fully in front of the reinforcing-bar cage \nC. The drill bit is actually underneath the plywood sheet, nowhere near the reinforcing bars \nD. The drill bit is behind the concrete wall and completely out of sight ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 1999.0, 1278.0], [695.0, 776.0, 1330.0, 909.0], [50.0, 50.0, 1923.90625, 302.0]]"}
{"question_id": 212, "image": "image_000212.jpg", "question": "A long articulated blue city bus is visible roughly in the centre of the photo, just to the left of the tallest red-brick tower. Relative to the stone road bridge on which it is travelling, where is the entire length of this bus located? ", "options": "A. Completely underneath the bridge, inside the stone archway \nB. Completely on the upper deck of the bridge (no part extends beyond the bridge's edges) \nC. Half of the bus is on the bridge while the rear half hangs over the river \nD. Parked on the riverside embankment below the bridge ", "answer": "B", "category": "Reasoning/Spatial Containment", "target_instances": "[[1133.0, 795.0, 1356.0, 835.0]]"}
{"question_id": 213, "image": "image_000213.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. On the expansive, uniformly mown green lawn that occupies the immediate foreground.\nB. Directly amongst the tall, dense green bushes that form a continuous line in front of the building.\nC. On the strip of gravel or paved pathway that is bordered by low flowerbeds and is located between the foreground lawn and a taller hedge of bushes.\nD. On the section of lawn that appears to be between the tall bushes and the base of the building.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[230.0, 541.0, 2067.0, 901.0], [67.0, 847.0, 2249.0, 992.0], [0.0, 960.0, 2249.0, 1080.0], [50.0, 50.0, 2161.9375, 338.0]]"}
{"question_id": 214, "image": "image_000214.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. It is suspended in front of, but not physically touching, the facade of the shorter, angular building.\nB. It is located entirely on the upper, metallic-looking facade of the shorter, angular building situated to the left of the very tall, tapered glass skyscraper.\nC. It is projected as a light display onto the lower glass section of the very tall, tapered glass skyscraper.\nD. It is partially on the shorter, angular building and partially extends onto the facade of the very tall, tapered glass skyscraper.", "answer": "B", "category": "Perception/OCR", "target_instances": "[[597.0, 132.0, 1474.0, 1996.0], [2.0, 1371.0, 676.0, 1996.0], [50.0, 50.0, 1447.90625, 446.0]]"}
{"question_id": 215, "image": "image_000215.jpg", "question": "Which distinct zone primarily contains the collection of numerous beige, thatched-roof sun umbrellas arranged in rows?", "options": "A. The turquoise water where people are swimming.\nB. The dense green forest covering the hillside.\nC. The area occupied by the multi-story white hotel with green roofs.\nD. The light-colored sandy beach area.", "answer": "D", "category": "Reasoning/Spatial Containment", "target_instances": "[[101.0, 837.0, 874.0, 1248.0], [727.0, 1099.0, 760.0, 1112.0], [728.0, 1080.0, 760.0, 1091.0]]"}
{"question_id": 216, "image": "image_000216.jpg", "question": "Is the white bird-like logo entirely contained within the visible blue painted surface of the large vertical tail fin of the Kuwait Airways plane?", "options": "A. No, the logo extends beyond the blue area onto the white part of the fuselage.\nB. Yes, the logo is fully within the blue area of the tail fin.\nC. No, the logo is partially on the blue tail fin and partially on the horizontal stabilizer.\nD. No, the logo is only on the white rudder section of the tail fin.", "answer": "B", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 287.0, 1937.0, 1499.0]]"}
{"question_id": 217, "image": "image_000217.jpg", "question": "Are the rows of brightly-colored handbags that are hanging on the metal rack completely inside the roofed market stall, or do any of them extend outside the stall's overhead roof?", "options": "A. They are completely inside the roofed stall space. \nB. About half of the bags extend outside the roofed space.\nC. Only the lowest row of bags is inside; the rest hang outside.\nD. All of the handbags are fully outside the covered stall.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[879.0, 597.0, 1076.0, 769.0], [478.0, 519.0, 1083.0, 664.0]]"}
{"question_id": 218, "image": "image_000218.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The small national flag flying on the roof of the tower \nB. The X-shaped silver cross-brace that spans several floors \nC. The curved head of the street-lamp in front of the building \nD. The upper leaves of the tallest foreground tree", "answer": "B", "category": "Perception/OCR", "target_instances": "[[117.0, 219.0, 1862.0, 1458.0], [50.0, 50.0, 1848.984375, 266.0]]"}
{"question_id": 219, "image": "image_000219.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The blue plastic crate nearest the camera on the left edge of the image. \nB. The series of small white connector pieces aligned along the middle of the belt. \nC. The diagonal white light tube being handed from one worker to another. \nD. The green conveyor belt surface itself. ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 704.0, 2247.0, 1496.0], [218.0, 957.0, 606.0, 1154.0], [50.0, 50.0, 2011.96875, 230.0]]"}
{"question_id": 220, "image": "image_000220.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The recessed entranceway of the multi-storey cream building \nB. The brick office block visible on the far right \nC. The metal bicycle rack area in front of the building \nD. The asphalt surface of the pedestrian crossing ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 1662.0, 810.0], [50.0, 50.0, 2111.828125, 230.0]]"}
{"question_id": 221, "image": "image_000221.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. He is on the right to the poster.\nB. He is on the left to the poster.\nC. He is standing above the poster.\nD. He is standing below the poster.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[617.0, 1802.0, 960.0, 2249.0], [0.0, 1657.0, 325.0, 1824.0], [50.0, 50.0, 1405.984375, 266.0]]"}
{"question_id": 222, "image": "image_000222.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. It is on the left of the orange building.\nB. It is on the right of the orange building.\nC. It is behind the orange building.\nD. It is on top of the orange building.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[229.0, 272.0, 1820.0, 1032.0], [1849.0, 528.0, 2246.0, 1118.0], [50.0, 50.0, 1817.96875, 230.0]]"}
{"question_id": 223, "image": "image_000223.jpg", "question": "Which object is entirely enclosed within the transparent glass-walled entrance vestibule located at the center of the panorama?", "options": "A. A red fire extinguisher standing on the floor beside the wall \n B. A beige curved sofa that faces the windows \n C. A set of green leaf-shaped chairs near the pizza counter \n D. The wooden service counter with the neon sign.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[1151.0, 956.0, 1447.0, 1065.0], [1370.0, 876.0, 1394.0, 945.0]]"}
{"question_id": 224, "image": "image_000224.jpg", "question": "Is the turquoise plastic water bottle standing next to the man in a black sleeveless vest positioned entirely on the very stone step on which he is sitting, without touching any other step? ", "options": "A. No, it is partly on the lower step. \nB. No, it is leaning against the wall above the step. \nC. Yes, the bottle is fully on that step. \nD. No, the bottle is resting on a cloth instead of the stone. ", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 1108.0, 2444.0, 1499.0], [287.0, 799.0, 619.0, 1188.0], [607.0, 1084.0, 640.0, 1179.0]]"}
{"question_id": 225, "image": "image_000225.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yes, it is entirely inside the office building. \nB. No, it stands completely outside and behind the office building. \nC. Yes, but only its lower floors are inside the office building. \nD. The two structures are actually the same building. ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[307.0, 295.0, 2613.0, 1277.0], [1418.0, 411.0, 1980.0, 671.0], [50.0, 50.0, 2548.953125, 266.0]]"}
{"question_id": 226, "image": "image_000226.jpg", "question": "Where is the decorated egg that has a mostly blue background with white zig-zags and red diamond shapes? ", "options": "A. Entirely inside the wicker basket among the greenery \nB. Half inside the basket with its lower half touching the stone step \nC. Balanced on top of the basket's curved handle \nD. Lying on the ground next to the black shoe ", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[794.0, 256.0, 1262.0, 898.0], [690.0, 531.0, 930.0, 815.0], [1146.0, 729.0, 1357.0, 869.0], [1130.0, 846.0, 1368.0, 976.0], [935.0, 769.0, 1112.0, 930.0]]"}
{"question_id": 227, "image": "image_000227.jpg", "question": "Where is the backpack in relation to the large, brown, yellow and white paraglider wing laid out on the snow in the picture?", "options": "A. The backpack is on top of the paraglider wing.\nB. The backpack is under the paraglider wing.\nC. The backpack is beside the paraglider wing.\nD. The backpack is far away from the paraglider wing.", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[1214.0, 721.0, 1766.0, 1195.0], [1098.0, 777.0, 1191.0, 844.0]]"}
{"question_id": 228, "image": "image_000228.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Right\nB. Left\nC. Top\nD. Opposite", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1989.0, 633.0, 2247.0, 857.0], [1337.0, 498.0, 1502.0, 651.0], [50.0, 50.0, 2159.953125, 266.0]]"}
{"question_id": 229, "image": "image_000229.jpg", "question": "The woman depicted from the side, wearing a bright yellow jacket, blue jeans, and carrying an orange tote bag on her right shoulder, is walking predominantly within which defined area of the scene?", "options": "A. On the expansive green lawn area containing numerous trees and lampposts.\nB. Inside the light-yellow, classical-style building with a green roof, located in the mid-ground.\nC. On the elevated, reddish-brown paved plaza area in the foreground, bordered by a low stone wall.\nD. On a pathway leading directly into the entrance of the tall glass skyscraper.", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[0.0, 1307.0, 554.0, 1481.0], [544.0, 1242.0, 630.0, 1482.0]]"}
{"question_id": 230, "image": "image_000230.jpg", "question": "Where is the black van with the yellow license plate situated in the overall street layout? ", "options": "A. On the narrow brick sidewalk next to the storefronts  \nB. Inside the glass-fronted shop under the yellow awning at the end of the street \nC. In a designated parking bay on the right-hand curb beyond the ambulance \nD. In the central vehicle travel lane of the street, between the sidewalks ", "answer": "D", "category": "Reasoning/Spatial Containment", "target_instances": "[[11.0, 1849.0, 1499.0, 2249.0], [710.0, 1786.0, 895.0, 1970.0]]"}
{"question_id": 231, "image": "image_000231.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yes, the hog is entirely inside that sandy ground area. \nB. No, part of the hog extends beyond the sandy ground area. \nC. The hog is partly outside the line of wooden posts. \nD. The hog is entirely outside the sandy ground area and wooden posts.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[2.0, 536.0, 2255.0, 1495.0], [822.0, 209.0, 1472.0, 1269.0], [50.0, 50.0, 2168.96875, 266.0]]"}
{"question_id": 232, "image": "image_000232.jpg", "question": "Which statement best describes the spatial relationship between the muscular stone figure (the kneeling man supporting the shell) and the lowest circular stone basin of the fountain? ", "options": "A. The kneeling figure is entirely contained inside the circular basin. \nB. The circular basin is entirely contained inside the kneeling figure. \nC. The kneeling figure and the basin partially overlap, with neither one fully containing the other. \nD. The kneeling figure is completely outside the circular basin. ", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[923.0, 109.0, 1664.0, 1222.0], [474.0, 1122.0, 2218.0, 1217.0]]"}
{"question_id": 233, "image": "image_000233.jpg", "question": "Which object is entirely enclosed within the black rectangular frame that hangs on the beige wall to the left side of the scene? ", "options": "A. The blue plastic rubbish bin standing on the floor \nB. The row of glowing ticket-vending machines \nC. The bright yellow information poster \nD. The stainless-steel turnstile with the left-pointing arrow sticker ", "answer": "C", "category": "Reasoning/Spatial Containment", "target_instances": "[[36.0, 499.0, 392.0, 870.0], [112.0, 564.0, 300.0, 817.0]]"}
{"question_id": 234, "image": "image_000234.jpg", "question": "Considering the woman on the right in black coat and jeans, what is her position relative to her bag?", "options": "A. She holds the bag in her right hand.\nB. She is carrying the bag on her left shoulder.\nC. She is carrying the bag on her right shoulder.\nD. She holds the bag in her left hand.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[1822.0, 829.0, 2084.0, 1475.0], [2049.0, 1183.0, 2139.0, 1395.0]]"}
{"question_id": 235, "image": "image_000235.jpg", "question": "What is the relative position of the black helmet and the yellow helmets?", "options": "A. It is among the yellow helmets.\nB. It is below the yellow helmets.\nC. It is above the yellow helmets.\nD. It is on the right of the yellow helmets.", "answer": "D", "category": "Reasoning/Spatial Containment", "target_instances": "[[1660.0, 231.0, 1890.0, 508.0], [715.0, 226.0, 948.0, 489.0], [959.0, 226.0, 1171.0, 480.0], [422.0, 212.0, 903.0, 483.0], [1417.0, 325.0, 1657.0, 498.0], [236.0, 228.0, 471.0, 470.0]]"}
{"question_id": 236, "image": "image_000236.jpg", "question": "Considering the man in the image, which description about him is right?", "options": "A. He wears a watch on his right hand and grasps a bunch of flower in his right hands.\nB. He wears a watch on his left hand and grasps a bunch of flower in his right hands.\nC. He wears a watch on his right hand and grasps a bunch of flower in his left hands.\nD. He wears a watch on his left hand and grasps a bunch of flower in his left hands.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[268.0, 0.0, 1538.0, 1496.0], [1020.0, 597.0, 1699.0, 1069.0]]"}
{"question_id": 237, "image": "image_000237.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. He is standing next to an old lady.\nB. He is standing below a streetlight.\nC. He is talking with a woman in pink dress.\nD. He is holding a baby carriage.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1109.0, 633.0, 1319.0, 1291.0], [794.0, 722.0, 1014.0, 970.0], [50.0, 50.0, 1830.0, 230.0]]"}
{"question_id": 238, "image": "image_000238.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. She is holding vegetables in her left hands.\nB. She is now swimming.\nC. She is feeding the food to lions.\nD. She is holding vegetables in her right hands.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1401.0, 598.0, 1747.0, 1008.0], [1564.0, 740.0, 1765.0, 885.0], [50.0, 50.0, 1543.0, 230.0]]"}
{"question_id": 239, "image": "image_000239.jpg", "question": "Which description about the image is right?", "options": "A. There is a man in red shirt pushing a stroller.\nB. There is a man riding a bicycle on the road.\nC. There is a woman in yellow dress with her dog next to her.\nD. There is a man in yellow shirt next to a man in green shirt, and they are talking.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[2511.0, 575.0, 2652.0, 761.0], [2603.0, 504.0, 2707.0, 748.0]]"}
{"question_id": 240, "image": "image_000240.jpg", "question": "Which description about the image is right?", "options": "A. There is a couple kissing each other.\nB. There is a couple hugging each other.\nC. There is a couple standing far apart from each other.\nD. There is a couple turning their backs on each other.", "answer": "A", "category": "Reasoning/Spatial Containment", "target_instances": "[[339.0, 862.0, 605.0, 1297.0], [270.0, 671.0, 621.0, 1285.0], [425.0, 719.0, 533.0, 843.0]]"}
{"question_id": 241, "image": "image_000241.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The bald eagle is flying above the man.\nB. The man in red shirt is holding a bald eagle in his hand.\nC. The man in red shirt is next to a bald eagle.\nD. The bald eagle is on the man's shoulder.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[304.0, 133.0, 1272.0, 1497.0], [481.0, 474.0, 2138.0, 1499.0], [50.0, 50.0, 1098.984375, 230.0]]"}
{"question_id": 242, "image": "image_000242.jpg", "question": "Considering the young woman on the left, with a dark blue skirt and a red lanyard around her neck, who is sitting on the floor and engaged in an activity involving green leaves, what is the color of her watch?", "options": "A. Black\nB. Pink\nC. White\nD. Blue", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[164.0, 933.0, 936.0, 1496.0]]"}
{"question_id": 243, "image": "image_000243.jpg", "question": "What color is the clothes worn by the man sitting on the bricks on the left side of the picture?", "options": "A. Black and white stripes\nB. Dark blue and white stripes\nC. Light blue and dark blue stripes\nD. Light blue and white stripes", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[538.0, 1001.0, 584.0, 1078.0]]"}
{"question_id": 244, "image": "image_000244.jpg", "question": "What color is the sign on the upper right side of the picture and with three flags above?", "options": "A. White and red\nB. Black and yellow\nC. Blue and whte\nD. Orange and black", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[2070.0, 216.0, 2116.0, 284.0]]"}
{"question_id": 245, "image": "image_000245.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Betwalk\nB. BetterWalk\nC. BetWalking\nD. BetterWalking", "answer": "A", "category": "Perception/OCR", "target_instances": "[[503.0, 1273.0, 542.0, 1319.0], [50.0, 50.0, 1779.953125, 230.0]]"}
{"question_id": 246, "image": "image_000246.jpg", "question": "What is the color of the top of the tall pagoda located on the left?", "options": "A. Yellow\nB. White\nC. Blue\nD. Red", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[219.0, 452.0, 260.0, 810.0]]"}
{"question_id": 247, "image": "image_000247.jpg", "question": "What color are the pants worn by the person with thinner hair, who is sitting on the riverbank in the lower right corner of the image?", "options": "A. Yellow\nB. White\nC. Gray\nD. Light Blue", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[2015.0, 1137.0, 2055.0, 1182.0]]"}
{"question_id": 248, "image": "image_000248.jpg", "question": "What color are the shoes worn by the tourist in the lower left corner of the image, who is walking briskly and wearing a dark blue long-sleeved top?", "options": "A. Black\nB. White\nC. Black and white\nD. Light yellow", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[507.0, 1614.0, 541.0, 1699.0]]"}
{"question_id": 249, "image": "image_000249.jpg", "question": "How many lighting units are visible at the bottom portion of the image?", "options": "A. One\nB. Two\nC. Three\nD. Zero", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[289.0, 2038.0, 362.0, 2134.0], [1117.0, 2061.0, 1187.0, 2158.0]]"}
{"question_id": 250, "image": "image_000250.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Black\nB. Red\nC. Pink\nD. Orange", "answer": "B", "category": "Perception/OCR", "target_instances": "[[339.0, 2082.0, 383.0, 2247.0], [50.0, 50.0, 1340.984375, 266.0]]"}
{"question_id": 251, "image": "image_000251.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yellow \nB. Blue \nC. Red \nD. Green ", "answer": "C", "category": "Perception/OCR", "target_instances": "[[2218.0, 845.0, 2391.0, 881.0], [50.0, 50.0, 2332.90625, 266.0]]"}
{"question_id": 252, "image": "image_000252.jpg", "question": "What is the predominant color of the group of horse-mounted statues located directly at the base of the column? \n  \n ", "options": "A. Bright gold  B. Matte black \nC. Bluish-green patina \nD. Silver-white ", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[855.0, 1506.0, 1174.0, 1706.0], [615.0, 1464.0, 828.0, 1707.0]]"}
{"question_id": 253, "image": "image_000253.jpg", "question": "What is the color of the sign on the right railway flagpole in the picture? ", "options": "A. Blue \nB. Red \nC. Green \nD. Yellow", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[1445.0, 335.0, 1506.0, 587.0]]"}
{"question_id": 254, "image": "image_000254.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Black \nB. Red \nC. Green \nD. Blue ", "answer": "D", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 2249.0, 1495.0], [50.0, 50.0, 2128.96875, 266.0]]"}
{"question_id": 255, "image": "image_000255.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Dark Blue\nB. Black\nC. Tan/Light Brown\nD. Red", "answer": "C", "category": "Perception/OCR", "target_instances": "[[816.0, 540.0, 2176.0, 1172.0], [50.0, 50.0, 2393.96875, 230.0]]"}
{"question_id": 256, "image": "image_000256.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Green and Blue\nB. Red and Black\nC. Yellow and Blue\nD. Red and Yellow", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1141.0, 1271.0, 1310.0, 1599.0], [50.0, 50.0, 1417.984375, 266.0]]"}
{"question_id": 257, "image": "image_000257.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Green \nB. Blue \nC. Black \nD. White ", "answer": "C", "category": "Perception/OCR", "target_instances": "[[605.0, 430.0, 757.0, 933.0], [50.0, 50.0, 2186.921875, 266.0]]"}
{"question_id": 258, "image": "image_000258.jpg", "question": "What is the tall structure positioned exactly at the geometric center of the circular plaza in the middle of the image?", "options": "A. A marble fountain \nB. A clock tower \nC. A bronze equestrian statue \nD. An ancient Egyptian obelisk ", "answer": "D", "category": "Perception/Attributes", "target_instances": "[[1106.0, 590.0, 1165.0, 757.0]]"}
{"question_id": 259, "image": "image_000259.jpg", "question": "What is the color of the two small, illuminated downward-pointing arrows that hang above the driveway entrance directly beneath the curved glass corner of the mall facade? ", "options": "A. Green \nB. Red \nC. Blue \nD. White ", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[377.0, 1158.0, 407.0, 1187.0]]"}
{"question_id": 260, "image": "image_000260.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Triangle \nB. Star \nC. Oval \nD. Square ", "answer": "C", "category": "Perception/OCR", "target_instances": "[[7.0, 1060.0, 968.0, 1610.0], [50.0, 50.0, 1447.9375, 266.0]]"}
{"question_id": 261, "image": "image_000261.jpg", "question": "At the food stall with brown signboard, what is the white three-digit number, indicating a price, prominently displayed on the black rectangular digital menu screen positioned directly above the food preparation counter and to the right of a graphic depicting a burger?", "options": "A. 299\nB. 189\nC. 199\nD. 259", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[456.0, 362.0, 567.0, 508.0]]"}
{"question_id": 262, "image": "image_000262.jpg", "question": "Which geometric motif forms the main part of the belt buckle at the center of the person waist? ", "options": "A. Single oval ring\nB. Twin interlocking circles\nC. Solid square frame\nD. Two rings", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[569.0, 134.0, 1087.0, 2102.0]]"}
{"question_id": 263, "image": "image_000263.jpg", "question": "How many cone-shaped evergreen bushes are clustered closely together directly in front of that light-blue-roofed pavilion?", "options": "A. Seven \nB. More than 10 and less than 15  \nC. More than 20 \nD. More than 15 and less than 20", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[1255.0, 752.0, 1448.0, 877.0], [1367.0, 823.0, 1421.0, 932.0]]"}
{"question_id": 264, "image": "image_000264.jpg", "question": "What is the woman doing next to the free khaki bench in the picture?", "options": "A. Reading a piece of paper \nB. Eating food \nC. Making a phone call\nD. Talking with friends", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[548.0, 1475.0, 613.0, 1615.0], [613.0, 1499.0, 669.0, 1612.0]]"}
{"question_id": 265, "image": "image_000265.jpg", "question": "What is the shape of the ornament fixed at the very peak of the tall, sharply pointed wooden spire that rises from the shingled roof of the foreground wooden building?", "options": "A. A sphere \nB. A star \nC. A cross\nD. A weather vane arrow", "answer": "D", "category": "Perception/Attributes", "target_instances": "[[344.0, 169.0, 1413.0, 1435.0], [1015.0, 36.0, 1066.0, 171.0]]"}
{"question_id": 266, "image": "image_000266.jpg", "question": "Observe the green rectangular road sign below the Starbucks sign on the large logo on the left side of the image, which is mounted on the same support pole. What is the first legible letter of the second word printed in white on this green sign?", "options": "A. S\nB. D\nC. T\nD. C", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[235.0, 163.0, 517.0, 1082.0]]"}
{"question_id": 267, "image": "image_000267.jpg", "question": "On the white fade bulding with five red shutters, there is a metal planter box mounted directly beneath the central window.  What is the color of the flowers in that planter?", "options": "A. White\nB. Purple\nC. Yellow\nD. Pink", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[491.0, 99.0, 1783.0, 1443.0], [1454.0, 835.0, 1552.0, 897.0]]"}
{"question_id": 268, "image": "image_000268.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Black\nB. White\nC. Lime green\nD. Burgundy", "answer": "B", "category": "Perception/OCR", "target_instances": "[[0.0, 1939.0, 1498.0, 2249.0], [69.0, 1927.0, 220.0, 2064.0], [249.0, 1893.0, 554.0, 2026.0], [50.0, 50.0, 1442.953125, 302.0]]"}
{"question_id": 269, "image": "image_000269.jpg", "question": "Near the upper-left area of the scene, a construction crane stands beside a low rooftop that displays a large word in block letters.  What are the last four letters of teh word on that rooftop sign?", "options": "A. ESON\nB. ESOL\nC. TSOL\nD. TSAL", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[35.0, 802.0, 222.0, 946.0], [0.0, 697.0, 262.0, 888.0]]"}
{"question_id": 270, "image": "image_000270.jpg", "question": "At the bottom left of the photo, there is a street-food cart with a striped umbrella. What is the color of the outermost (top) stripe of that umbrella? ", "options": "A. Blue \nB. Yellow \nC. Green \nD. White ", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[170.0, 1264.0, 282.0, 1293.0]]"}
{"question_id": 271, "image": "image_000271.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Deep blue \nB. Bright red \nC. Pale gray \nD. Lime green ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[250.0, 1105.0, 648.0, 1251.0], [50.0, 50.0, 2154.9375, 266.0]]"}
{"question_id": 272, "image": "image_000272.jpg", "question": "What object is at the bottom left side of the picture, on the pole and besides the tree?", "options": "A. Street Light\nB. TV tower\nC. Building\nD. Tower", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[502.0, 1217.0, 593.0, 1399.0]]"}
{"question_id": 273, "image": "image_000273.jpg", "question": "On the roofline area just to the left of the tall white building on the right edge of the image, a single small rooftop structure is visible among the trees. Which geometric shape best describes that structure? ", "options": "A. Square \nB. Octagon \nC. Circle \nD. Triangle ", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[1747.0, 490.0, 1855.0, 634.0]]"}
{"question_id": 274, "image": "image_000274.jpg", "question": "At the bottom-center of the picture, directly in front of the nearest dark-green, cube-shaped topiary bush, what is the color of the single plastic chair with a slatted ", "options": "A. Brown \nB. White \nC. Dark Green \nD. Light Blue ", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[1079.0, 1394.0, 1305.0, 1499.0]]"}
{"question_id": 275, "image": "image_000275.jpg", "question": "What is the girl wearing while sitting on the chair in the center of the image, which is partially obscured by a tall street light?", "options": "A. Pink shoes\nB. White skirt\nC. Light blue skirt\nD. Black shoes", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[830.0, 1141.0, 945.0, 1278.0]]"}
{"question_id": 276, "image": "image_000276.jpg", "question": "What color is the cap located in the center of the image?", "options": "A. Black and red\nB. Dark red\nC. Dark purple\nD. Black and purple", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[751.0, 654.0, 855.0, 715.0]]"}
{"question_id": 277, "image": "image_000277.jpg", "question": "According to the clock in the image, what time is it now?", "options": "A. 7:07\nB. 8:07\nC. 7:13\nD. 8:13", "answer": "A", "category": "Perception/Attributes", "target_instances": "[[1879.0, 245.0, 2071.0, 420.0]]"}
{"question_id": 278, "image": "image_000278.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Between the first lane and the second lane\nB. Between the second lane and the third lane\nC. Between the third lane and the fourth lane\nD. Between the fourth lane and the fifth lane.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[966.0, 474.0, 1228.0, 1386.0], [50.0, 50.0, 2121.984375, 266.0]]"}
{"question_id": 279, "image": "image_000279.jpg", "question": "What is the color of the vehicle positioned in front of the building in the upper right corner of the image?", "options": "A. Black and white\nB. Black and red\nC. Brown and red\nD. Black", "answer": "B", "category": "Perception/Attributes", "target_instances": "[[2132.0, 268.0, 2200.0, 304.0]]"}
{"question_id": 280, "image": "image_000280.jpg", "question": "What activity is the woman engaged in, who is located in the lower left corner of the image near to the flag and dressed in a white upper garment and black trousers?", "options": "A. Being photographed by others\nB. Photographing others\nC. Chatting with others\nD. Viewing the distance through a telescope", "answer": "D", "category": "Perception/Attributes", "target_instances": "[[383.0, 1075.0, 433.0, 1194.0]]"}
{"question_id": 281, "image": "image_000281.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Smile\nB. Grin\nC. Cry\nD. Angry", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1832.0, 1232.0, 1883.0, 1314.0], [50.0, 50.0, 2192.921875, 266.0]]"}
{"question_id": 282, "image": "image_000282.jpg", "question": "What is the color of the third dress from the right-hand side, located in the upper right corner of the image?", "options": "A. Blue and white\nB. Red and white\nC. Black and white\nD. Black and red", "answer": "C", "category": "Perception/Attributes", "target_instances": "[[1118.0, 449.0, 1211.0, 631.0]]"}
{"question_id": 283, "image": "image_000283.jpg", "question": "Considering the traditional beach chair with a high back and enclosed sides, located among other similar chairs facing the sea, what is the primary material used for constructing this chair?", "options": "A. Metal \nB. Plastic \nC. Wicker/Rattan \nD. Fabric ", "answer": "C", "category": "Perception/Material", "target_instances": "[[620.0, 1156.0, 730.0, 1301.0], [1504.0, 1124.0, 1594.0, 1232.0], [450.0, 1108.0, 535.0, 1204.0], [1131.0, 1109.0, 1253.0, 1229.0], [1188.0, 1105.0, 1272.0, 1193.0]]"}
{"question_id": 284, "image": "image_000284.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Wood \nB. Marble\nC. Plastic \nD. Ceramic ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[0.0, 2.0, 2434.0, 1370.0], [50.0, 50.0, 1793.96875, 230.0]]"}
{"question_id": 285, "image": "image_000285.jpg", "question": "In the middle of three people, the cetner woman is holding a phone, what type material of her upper body wearing?", "options": "A. Nylon\nB. Cotton fabric\nC. Plastic\nD. Down", "answer": "B", "category": "Perception/Material", "target_instances": "[[408.0, 790.0, 463.0, 1014.0]]"}
{"question_id": 286, "image": "image_000286.jpg", "question": "Considering its sheen, slight imperfections, and the way light reflects off it, what is the most likely material and surface finish of the large, cylindrical pot situated in the lower right section of the image, partially visible behind the glass enclosure?", "options": "A Cast iron \nB Polished copper with a high-gloss, reddish finish\nC Stainless steel with a brushed \nD Ceramic with a smooth, glazed white coating", "answer": "C", "category": "Perception/Material", "target_instances": "[[1722.0, 1175.0, 2249.0, 1469.0]]"}
{"question_id": 287, "image": "image_000287.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A Fired ceramic pieces\nB Bleached wood fragments\n C Natural stones \nD Smooth concrete casts", "answer": "C", "category": "Perception/OCR", "target_instances": "[[0.0, 851.0, 1695.0, 1476.0], [50.0, 50.0, 2192.921875, 266.0]]"}
{"question_id": 288, "image": "image_000288.jpg", "question": "The white plate in the foreground, adorned with a light brown geometric pattern and holding the falafel, most likely has which type of surface finish?", "options": "A High-gloss.\nB Matte.\nC Textured, non-shlip sillicone.\nD Glass-like.", "answer": "A", "category": "Perception/Material", "target_instances": "[[667.0, 161.0, 1498.0, 675.0]]"}
{"question_id": 289, "image": "image_000289.jpg", "question": "What materials are made for the objects above the stall?", "options": "A. Wood-aware products.\nB. Gray stone.\nC. Wood and Leacher product.\nD. Textile-aware product ", "answer": "C", "category": "Perception/Material", "target_instances": "[[859.0, 1044.0, 1090.0, 1281.0]]"}
{"question_id": 290, "image": "image_000290.jpg", "question": "What the materials for the bottles on the bike?", "options": "A. Plastic.\nB. White Glass.\nC. Bronze-aware product\nD. Insulation material", "answer": "D", "category": "Perception/Material", "target_instances": "[[811.0, 289.0, 1047.0, 841.0], [483.0, 270.0, 863.0, 690.0]]"}
{"question_id": 291, "image": "image_000291.jpg", "question": "Considering the large building with green roofs and white walls situated near the beach, what is the most likely material used for the exterior walls", "options": " A. Concrete \n B. Wood \n C. Glass \n D. Brick ", "answer": "A", "category": "Perception/Material", "target_instances": "[[1006.0, 675.0, 1745.0, 867.0]]"}
{"question_id": 292, "image": "image_000292.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Recently installed, artificially textured concrete pavers with a matte sealant.\nB. Natural stone setts (cobblestones).\nC. Cast iron blocks with a deliberately roughened, non-slip surface, showing signs of superficial rust.\nD. Extruded plastic composite blocks designed to mimic stone, exhibiting uniform color and minimal surface degradation.", "answer": "B", "category": "Perception/OCR", "target_instances": "[[466.0, 0.0, 1497.0, 1757.0], [50.0, 50.0, 1440.953125, 446.0]]"}
{"question_id": 293, "image": "image_000293.jpg", "question": "Based on the reflections and sheen, what is the most likely primary material and finish combination of the tall, gooseneck kitchen faucet prominently positioned in the center foreground, above the stainless steel sink?", "options": "A. Polished brass\nB. Brushed stainless steel\nC. Matte black coated alloy\nD. Oil-rubbed bronze", "answer": "B", "category": "Perception/Material", "target_instances": "[[819.0, 709.0, 1113.0, 1497.0]]"}
{"question_id": 294, "image": "image_000294.jpg", "question": "The two ornate, golden, footed offering trays, visible on the red patterned floor covering to the right of the kneeling monk, exhibit a highly reflective, warm-toned metallic sheen. What is their most probable primary material or surface coating?", "options": "A. Polished brass or a similar gold-toned metal/alloy\nB. High-gloss yellow ceramic with a lustrous glaze\nC. Gold-colored lacquer applied over carved wood\nD. Vacuum-metalized plastic with a clear protective coat", "answer": "C", "category": "Perception/Material", "target_instances": "[[1528.0, 1043.0, 1808.0, 1236.0], [1803.0, 1103.0, 2020.0, 1235.0]]"}
{"question_id": 295, "image": "image_000295.jpg", "question": "Considering the pathway in the foreground leading towards the building, which is composed of flat, irregularly shaped units with visible gaps between them, what is the most probable material and its dominant surface characteristic?", "options": "A. Poured and scored concrete, with a uniformly rough, brushed texture\nB. Natural stone slabs (flagstones), displaying inherent color variations and a relatively matte, slightly uneven surface\nC. Dark asphalt, with a smooth, compacted surface\nD. Interlocking rubber pavers, exhibiting a consistent dark color and a slightly yielding, patterned surface", "answer": "B", "category": "Perception/Material", "target_instances": "[[1424.0, 1312.0, 1815.0, 1498.0]]"}
{"question_id": 296, "image": "image_000296.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Polished Marble with intricate veining\nB. Glazed Terracotta Bricks with a high-gloss finish\nC. Dressed Limestone or Sandstone blocks with a smooth, matte finish with light red\nD. Rough-hewn Timber Beams, stained light red", "answer": "C", "category": "Perception/OCR", "target_instances": "[[1271.0, 0.0, 2255.0, 1382.0], [50.0, 50.0, 2202.90625, 338.0]]"}
{"question_id": 297, "image": "image_000297.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A matte, bead-blasted finish, resulting in a uniformly dull, non-reflective surface designed to minimize glare.\nB. Galvanization with a visible zinc spangle pattern, giving it a mottled, crystalline appearance for corrosion protection.\nC. A polished or bright annealed finish, creating a smooth, highly reflective, and lustrous surface.\nD. Coated with a clear, thick lacquer over a roughly sanded base metal, causing light to scatter unevenly and show sanding marks.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[0.0, 0.0, 546.0, 1495.0], [50.0, 50.0, 2551.90625, 266.0]]"}
{"question_id": 298, "image": "image_000298.jpg", "question": "In this figure, the man are sitting on a chair. What kinds of materials are for these chairs ?", "options": "A. White color glasses.\nB. Wooden.\nC. Plastic.\nD. Iron products.", "answer": "B", "category": "Perception/Material", "target_instances": "[[1002.0, 448.0, 1117.0, 587.0], [928.0, 455.0, 1028.0, 601.0]]"}
{"question_id": 299, "image": "image_000299.jpg", "question": "Considering the two white, U-shaped structures with flat top panels installed in the paved area in the foreground, what is the most likely material and surface treatment applied to them?", "options": "A. Carved stone with a naturally matte finish.\nB. Plastic molding with an inherently glossy surface.\nC. Wood, coated with a transparent varnish.\nD. Metal, covered with a thick layer of opaque white paint.", "answer": "C", "category": "Perception/Material", "target_instances": "[[371.0, 931.0, 608.0, 1274.0], [533.0, 923.0, 647.0, 1228.0]]"}
{"question_id": 300, "image": "image_000300.jpg", "question": "The bright white, block-style letters forming the \"PRINCE SHOPPING PLAZA\" sign, positioned on the green lawn, are most likely fabricated from which material, considering their smooth, uniform surface and exceptionally high brightness in the evening light?", "options": "A. Cast concrete, painted with high-gloss white paint\nB. Polished white marble, reflecting ambient light\nC. Fabricated sheet metal with a standard matte white coating\nD. Internally illuminated ", "answer": "D", "category": "Perception/Material", "target_instances": "[[330.0, 806.0, 662.0, 861.0]]"}
{"question_id": 301, "image": "image_000301.jpg", "question": "The large white boat with red accents, docked at the pier extending into the water. What can be inferred about its current operational status based on its physical appearance?", "options": "A. The boat is in active service, with no visible signs of disrepair, and is likely being used for regular cargo or passenger transport. \nB. The boat is out of service, showing signs of rust and decay, and is likely abandoned or awaiting repair. \nC. The boat is partially operational, with some visible damage but still capable of limited use, possibly for short-distance travel. \nD. The boat is under renovation, with scaffolding and construction materials visible, indicating ongoing maintenance work.", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[1394.0, 470.0, 1861.0, 559.0]]"}
{"question_id": 302, "image": "image_000302.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The raincoat's hood is up and covering the head. \nB. The man are not wearing any form of hat or hood. \nC. The raincoat's hood is down, resting on his shoulders. \nD. He is holding a separate hat, but not wearing it.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[2315.0, 1232.0, 2402.0, 1366.0], [50.0, 50.0, 2501.90625, 266.0]]"}
{"question_id": 303, "image": "image_000303.jpg", "question": "What is the opening state of the translucent blue folder positioned beneath the sheet of paper with printed text? ", "options": "A. Fully open with pages exposed \nB. Half-open like a tent \nC. Completely closed and lying flat \nD. Folded in half lengthwise ", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[779.0, 1183.0, 1217.0, 1385.0]]"}
{"question_id": 304, "image": "image_000304.jpg", "question": "What is the condition of the rear cargo door on the small white box-shaped truck parked in the leftmost lane beside the row of orange traffic cones?", "options": "A. Fully closed and latched \nB. Fully open upward \nC. Half-open (partially raised) \nD. Missing entirely ", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[290.0, 2141.0, 378.0, 2222.0]]"}
{"question_id": 305, "image": "image_000305.jpg", "question": "What is the physical state of the door located up the small set of stairs on the right-hand building, positioned to the right of the large, illuminated storefront window? ", "options": "A. The door is wide open. \nB. The door is slightly ajar. \nC. The door is closed. \nD. The door is completely missing from its frame.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[1759.0, 1084.0, 1795.0, 1290.0]]"}
{"question_id": 306, "image": "image_000306.jpg", "question": "What is the condition of the top section of the tall, dark blue skyscraper located to the immediate left of the reddish-brown, mesh-covered building?", "options": "A. The top section is visibly crumbling and in a state of disrepair. \nB. It is a simple, flat roof with no distinct features. \nC. It features a complete, multi-layered architectural design with distinct vertical segments. \nD. A large crane is currently situated on top, indicating ongoing construction.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[1033.0, 739.0, 1127.0, 923.0]]"}
{"question_id": 307, "image": "image_000307.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Its mouth is wide open, as if it is neighing. B. It is missing its lower jaw. C. Its mouth is firmly closed. D. It is chewing on a piece of stone grass.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[1035.0, 1013.0, 1299.0, 1210.0], [50.0, 50.0, 1421.9375, 194.0]]"}
{"question_id": 308, "image": "image_000308.jpg", "question": "Observe the small transparent plastic cup resting on the lowest concrete step. Which statement best describes its fill level? ", "options": "A. The cup is tipped on its side and empty \nB. Roughly one-quarter to one-third of the cup is filled with a dark liquid \nC. The cup is completely full to the brim \nD. The cup is crushed flat with no liquid inside ", "answer": "B", "category": "Perception/Physical State", "target_instances": "[[782.0, 2121.0, 835.0, 2221.0]]"}
{"question_id": 309, "image": "image_000309.jpg", "question": "Based on the visual evidence, what is the state of the main passenger door on the large white bus in the background? ", "options": "A. The door is wide open. \nB. The door is visibly damaged and dented. \nC. The door is in a fully closed and sealed position. \nD. The door is partially ajar.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[961.0, 82.0, 1573.0, 611.0]]"}
{"question_id": 310, "image": "image_000310.jpg", "question": "What is the physical state of the metal roller shutter located to the immediate right of the leftmost visible metal roller shutter on the white building?", "options": "A. It is completely closed. \nB. It has significant rust and corrosion. C. It is partially open at the bottom. \nD. It is fully open.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[596.0, 579.0, 714.0, 722.0]]"}
{"question_id": 311, "image": "image_000311.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. It is dry and dusty. \nB. It is covered with a fresh layer of asphalt. \nC. It is wet. \nD. It is made of light-colored concrete.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[0.0, 1068.0, 1498.0, 1874.0], [50.0, 50.0, 1330.984375, 266.0]]"}
{"question_id": 312, "image": "image_000312.jpg", "question": "What is the operational state of the large vertical sign on the right side of the image that displays the red \"ABC MART\" logo?", "options": "A. Only the letter 'A' at the top is illuminated. \nB. There is a large, visible crack running across the sign's surface. \nC. The sign is evenly illuminated and appears to be functioning correctly. \nD. The sign's internal light is off, and its visibility comes from the reflection of surrounding lights.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[1672.0, 397.0, 1886.0, 518.0]]"}
{"question_id": 313, "image": "image_000313.jpg", "question": "Based on the image, what is the current state of the right pedal on the bicycle being ridden by the man with short hair on a blackish T-shirt?", "options": "A. It is at the highest point of its rotation. B. It is in the rearmost position of its rotation. \nC. It is at the lowest point of its rotation. \nD. It is in the forward-most position of its rotation.", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[0.0, 833.0, 478.0, 1283.0]]"}
{"question_id": 314, "image": "image_000314.jpg", "question": "Examine the stacks of large, grey, round items on the top shelf on the far left. What is the physical shape of the stack positioned at the very end of the shelf?", "options": "A. It appears compressed and is bulging outwards at the sides. \nB. It is perfectly cylindrical. \nC. It is visibly torn down one side. \nD. The stack is about to fall.", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[231.0, 286.0, 382.0, 505.0]]"}
{"question_id": 315, "image": "image_000315.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Most shades appear to be closed or partially closed B. Most shades are fully open\nC. All shades are uniformly open in a fixed pattern", "answer": "B", "category": "Perception/OCR", "target_instances": "[[89.0, 474.0, 2238.0, 1050.0], [50.0, 50.0, 2145.953125, 194.0]]"}
{"question_id": 316, "image": "image_000316.jpg", "question": " Is the head of the terracotta warrior lying on its back in the middle of the scene still connected to its neck? ", "options": "A. Yes, the head remains attached to the neck. \nB. No, the head has broken off and lies beside the torso. \nC. The head is missing entirely from the pit. \nD. The head has been re-secured with visible metal supports. ", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[302.0, 425.0, 1500.0, 1494.0]]"}
{"question_id": 317, "image": "image_000317.jpg", "question": "Observe the tall white lamppost rising just left of the image center background. How is the pole aligned?", "options": " A. Slightly leaning to the left \nB. Perfectly vertical \nC. Leaning noticeably to the right \nD. Broken halfway up ", "answer": "B", "category": "Perception/Physical State", "target_instances": "[[430.0, 463.0, 460.0, 663.0]]"}
{"question_id": 318, "image": "image_000318.jpg", "question": "What is the posture of the golden-brown dog standing near the tree line beside the parked cars on the right side of the walkway?", "options": "A. Lying on its side \nB. Standing on all four legs with its head lowered \nC. Sitting upright on its hind legs \nD. Leaping with all four paws off the ground ", "answer": "B", "category": "Perception/Physical State", "target_instances": "[[1573.0, 1065.0, 1718.0, 1233.0]]"}
{"question_id": 319, "image": "image_000319.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. No visible exhaust or vapor at all \nB. A faint white exhaust plume drifting upward \nC. A thick column of black smoke pouring out \nD. Blue flames shooting from the tailpipe ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[1006.0, 1021.0, 1421.0, 1279.0], [50.0, 50.0, 2261.0, 230.0]]"}
{"question_id": 320, "image": "image_000320.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A faint grey plume of dust or smoke \nB. A stream of water spraying upward \nC. Bright orange flames \nD. No visible plume or emission ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[1053.0, 1101.0, 1323.0, 1256.0], [50.0, 50.0, 2144.953125, 266.0]]"}
{"question_id": 321, "image": "image_000321.jpg", "question": "What is the position of the lid on the green dumpster located beside the low stone pillars halfway up the hill?", "options": "A. Fully closed and flat \nB. Partially open, tilted upward \nC. Completely open, standing vertical \nD. The lid is missing ", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[966.0, 1026.0, 1070.0, 1129.0]]"}
{"question_id": 322, "image": "image_000322.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The leg is cracked in the middle. \nB. The leg appears to be well-maintained with no visible damage. \nC. The bottom of the leg is significantly chipped and worn. \nD. The leg is detached from the tabletop.", "answer": "C", "category": "Perception/OCR", "target_instances": "[[1317.0, 56.0, 1827.0, 523.0], [50.0, 50.0, 1933.96875, 266.0]]"}
{"question_id": 323, "image": "image_000323.jpg", "question": "What is the motion state of the person wearing a red jacket and riding a bicycle on the far-right side of the image? ", "options": "A. Standing still with both feet on the ground beside the bicycle \nB. Dismounted and walking while pushing the bicycle \nC. Actively riding and moving forward on the bicycle \nD. Sitting on the bike but waiting at a complete stop with one foot on a pedal ", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[2610.0, 909.0, 2650.0, 970.0]]"}
{"question_id": 324, "image": "image_000324.jpg", "question": "Focusing on the man standing at the far right edge of the group (he is wearing a pale pink-lavender jacket and dark trousers), what is the position of the zipper?", "options": "A. Completely unzipped \nB. Zipper is broken and detached \nC. Fully zipped up to the collar \nD. Partially zipped, leaving the upper section open ", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[1043.0, 1090.0, 1210.0, 1724.0]]"}
{"question_id": 325, "image": "image_000325.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Slightly open with several white teeth exposed. \nB. Completely closed with no teeth showing. \nC. Wide open with a red tongue protruding. \nD. Torn open, exposing internal stuffing. ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[47.0, 241.0, 999.0, 1496.0], [50.0, 50.0, 1864.96875, 230.0]]"}
{"question_id": 326, "image": "image_000326.jpg", "question": "What is the current state of the soccer ball located near the lower-right portion of the field? ", "options": "A. Rolling along the grass \n B. Resting motionless on the ground \n C. Suspended in mid-air \n D. Trapped under the white-uniformed player's boot ", "answer": "A", "category": "Perception/Physical State", "target_instances": "[[1530.0, 1002.0, 1628.0, 1098.0]]"}
{"question_id": 327, "image": "image_000327.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Fully closed and latched\nB. Completely detached and lying beside the chest\nC. Propped open at an acute angle\nC. Open flat, parallel to the floor", "answer": "C", "category": "Perception/OCR", "target_instances": "[[439.0, 940.0, 574.0, 1086.0], [50.0, 50.0, 2025.96875, 266.0]]"}
{"question_id": 328, "image": "image_000328.jpg", "question": "Regarding the dark metallic-blue Vespa immediately to the right of the mint-green one (its rider wears a white tank-top and jeans), how is the large black protective bag positioned on the scooter__ leg-shield?", "options": "A. No bag is attached to the scooter\n B. The bag is strapped only to the right edge, leaving most of the leg-shield exposed\n C. The bag is fixed behind the rider on the rear rack\n D. The bag is draped across and fully covers the central leg-shield but does not obscure the head-light", "answer": "D", "category": "Perception/Physical State", "target_instances": "[[1180.0, 783.0, 1364.0, 1030.0]]"}
{"question_id": 329, "image": "image_000329.jpg", "question": "What is the state of the opening of the small, transparent plastic bag filled with red berries, which is nestled within the larger container of dark blue berries in the middle row, second from the left?", "options": "A. Tightly sealed with a twist-tie\nB. Open at the top\nC. Torn open at the bottom\nD. Neatly folded and stapled shut", "answer": "B", "category": "Perception/Physical State", "target_instances": "[[916.0, 489.0, 1208.0, 673.0]]"}
{"question_id": 330, "image": "image_000330.jpg", "question": "What is the physical posture of the boy in the red shirt on the grassy hill at the far top left?", "options": "A. He is standing and watching the performance. B. He is lying down flat on the grass. \nC. He is in the middle of running down the hill. \nD. He is sitting with his knees bent.", "answer": "D", "category": "Perception/Physical State", "target_instances": "[[124.0, 491.0, 172.0, 561.0]]"}
{"question_id": 331, "image": "image_000331.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. It is covered with a tarp. \nB. It is empty. \nC. It is half-full of gravel. \nD. It is loaded with boxes.", "answer": "B", "category": "Perception/OCR", "target_instances": "[[220.0, 883.0, 771.0, 1202.0], [50.0, 50.0, 1838.921875, 230.0]]"}
{"question_id": 332, "image": "image_000332.jpg", "question": "What is the operational state of the traffic light suspended by wires over the tram tracks in the center of the street?", "options": "A. The yellow light is on. \nB. All the lights are off. \nC. The green light is on. \nD. The red light is on.\n", "answer": "D", "category": "Perception/Physical State", "target_instances": "[[980.0, 676.0, 1037.0, 705.0]]"}
{"question_id": 333, "image": "image_000333.jpg", "question": "What is the physical state of the white bag situated on the reddish-brown earthen bank on the far left?", "options": "A. It is being carried by a worker. \nB. It is torn open with its contents spilling out. \nC. It is propped upright against the bank. \nD. It is empty and lying flat on the ground.", "answer": "C", "category": "Perception/Physical State", "target_instances": "[[185.0, 646.0, 324.0, 743.0]]"}
{"question_id": 334, "image": "image_000334.jpg", "question": "Considering the spatial layout of the museum lobby, which object is closer to the \"Talks & Tours\" sign than the woman in the dark blue sleeveless top?", "options": "A. The man in the dark gray t-shirt walking behind the \"Information on the Getty Villa\" sign \nB. The potted orchid with white flowers placed on the counter \nC. The woman in the blue t-shirt and denim shorts near the information desk \nD. The man in the light blue long-sleeve shirt with a black cap ", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[1571.0, 744.0, 1761.0, 1327.0], [1127.0, 485.0, 1176.0, 873.0], [1154.0, 689.0, 1310.0, 844.0]]"}
{"question_id": 335, "image": "image_000335.jpg", "question": "Considering the relative distances from the edge of the pond, which object is closest to the edge of the pond?", "options": "A. The vibrant yellow iris plant in the round pot, approximately 2-3 feet tall, situated in the pond.\nB. The classical white statue of a human figure, standing on a pedestal near the pond.\nC. The medium-sized green aquatic plant in a wire mesh cage, floating in the pond.\nD. The person in black watching the middle of the pool.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[525.0, 901.0, 645.0, 1065.0], [907.0, 869.0, 1013.0, 1011.0]]"}
{"question_id": 336, "image": "image_000336.jpg", "question": "Considering the relative distances in the image, which object is closer to the police officer holding the ice cream cone?", "options": "A. The tree behind the bus stop \nB. The black bollard on the sidewalk \nC. The police van parked on the side of the road \nD. The bus stop sign ", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[298.0, 230.0, 1026.0, 1499.0], [0.0, 111.0, 394.0, 947.0], [401.0, 0.0, 590.0, 370.0]]"}
{"question_id": 337, "image": "image_000337.jpg", "question": "Considering the relative distances from the large, green broadleaf tree near the modern building to the leafless tree with spread-out branches and to T-junction road, which statement is true?", "options": "A. The large, green broadleaf tree is closer to the leafless tree than to the paved pathway. \nB. The large, green broadleaf tree is equidistant from the leafless tree and the paved pathway. \nC. The large, green broadleaf tree is farther from the leafless tree than from the paved pathway. \nD. The paved pathway is closer to the leafless tree than to the large, green broadleaf tree.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[564.0, 1089.0, 955.0, 1528.0], [863.0, 736.0, 1312.0, 1526.0]]"}
{"question_id": 338, "image": "image_000338.jpg", "question": "Look at the bright violet-pink leotard worn by the left-hand mannequin under the red-and-white umbrella on the right side.   Which object in the scene shows a colour most similar to that leotard?", "options": "A. The T-shirt of the woman standing next to the mannequins beneath the same umbrella.\nB. The jacket of the boy in a vivid top walking toward the left foreground.\nC. The plastic shopping bag carried by the woman in patterned trousers heading away from the camera.\nD. The fabric item hanging under the house in the distance", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[241.0, 767.0, 438.0, 1270.0], [0.0, 819.0, 115.0, 1233.0], [1668.0, 691.0, 1760.0, 982.0], [346.0, 916.0, 447.0, 1097.0], [1606.0, 717.0, 1690.0, 908.0], [1956.0, 609.0, 1992.0, 722.0]]"}
{"question_id": 339, "image": "image_000339.jpg", "question": "Which is closer to the woman in blue jeans, the street lamp next to the terracotta pot or the street lamp next to the man squatting?", "options": "A. The street lamp next to the terracotta pot\nB. The same\nC. The street lamp next to the man squatting  \nD. cannot be judged from the photograph.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[1042.0, 1064.0, 1106.0, 1317.0], [1263.0, 1276.0, 1324.0, 1443.0], [453.0, 1104.0, 506.0, 1303.0], [1126.0, 1255.0, 1163.0, 1302.0], [332.0, 1278.0, 365.0, 1307.0], [377.0, 1278.0, 409.0, 1307.0]]"}
{"question_id": 340, "image": "image_000340.jpg", "question": "Which object overall color most closely matches the dark grey paint of the large helicopter fuselage?", "options": "A. The jacket of the man with the camera\nB. The grassy field at the bottom right foreground where spectators are sitting in a hat.\nC. The fighter jet parked behind the helicopter tail.\nD. The T-shirt of the nearest sitting little boy", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[2.0, 352.0, 2249.0, 921.0], [1549.0, 719.0, 2153.0, 829.0], [1252.0, 877.0, 1387.0, 1210.0], [1954.0, 1022.0, 2154.0, 1236.0], [1148.0, 1163.0, 1280.0, 1367.0]]"}
{"question_id": 341, "image": "image_000341.jpg", "question": "Which object is physically closer to the white building with a poster?", "options": "A. The large red-hulled ship moored at the extreme bottom-right corner of the quay \nB. The small orange rescue craft tied farther up the same quay, near the top-right edge of the frame \nC. The solar panel array \nD. The white passenger ferry docked near the far right horizon, behind the orange craft ", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[1496.0, 745.0, 1763.0, 880.0], [0.0, 1069.0, 340.0, 1144.0], [1826.0, 1051.0, 1997.0, 1204.0], [2197.0, 983.0, 2257.0, 1046.0], [1999.0, 857.0, 2100.0, 888.0]]"}
{"question_id": 342, "image": "image_000342.jpg", "question": "Based only on the visuals in the figure, which of the following objects is closer to the solitary bird on the far left of the figure\u5697", "options": "A. The blue car \nB. The green truck wingspan.         \nC. Road sign     \nD. It is impossible to determine from the image.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[114.0, 878.0, 228.0, 1277.0], [2042.0, 1046.0, 2088.0, 1082.0], [1975.0, 1044.0, 2013.0, 1082.0], [515.0, 531.0, 554.0, 560.0]]"}
{"question_id": 343, "image": "image_000343.jpg", "question": "Consider Point A as the very lowest metallic tip of the spout of the silver teapot from which liquid is currently being poured.   Let Point B be the closest point on the top rim of the plain, clear glass tumbler directly beneath the pouring spout, and Point C be the red decorative bowl on the small table. How does the straight-line real distance A-B compare to the straight-line real distance A-C in the image?", "options": "A. The distance A-B is much greater than the distance A-C\nB. The distance A-B is approximately equal to the distance A-C\nC. The distance A-B is much less than the distance A-C\nD. It is impossible to determine from the image", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[402.0, 484.0, 573.0, 721.0], [63.0, 105.0, 400.0, 317.0], [450.0, 981.0, 530.0, 1055.0], [187.0, 85.0, 291.0, 132.0]]"}
{"question_id": 344, "image": "image_000344.jpg", "question": "Which object lies farthest to the white circular button with a green (tick) situated above the blue directional-arrow padiny?", "options": "A. It is impossible to determine from the image\nB. The monitor on the back shelf\nC. Round green status-LED that sits just below the centre of the front-panel keypad\nD. The tall rectangular white barcode sticker fixed to the left-hand side of the device housing", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[319.0, 339.0, 1848.0, 1452.0], [1377.0, 199.0, 1671.0, 348.0]]"}
{"question_id": 345, "image": "image_000345.jpg", "question": "Which area in the scene shows a color most similar to the deep red of the woman headscarf?", "options": "A. The stems of harvested rice piled behind her\nB. The flower clusters printed on the upper half of her floral blouse\nC. The grey fishing-net-like fabric lying on the ground near her feet\nD. A small light brown wooden triangular support on the ground", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 875.0, 1496.0, 2070.0], [0.0, 357.0, 1495.0, 1006.0], [672.0, 749.0, 1437.0, 1932.0], [459.0, 1535.0, 1049.0, 1952.0]]"}
{"question_id": 346, "image": "image_000346.jpg", "question": "Which clothing item is closest in color to the brown red stone wall behind the people?", "options": "A. The blue coat worn by the seated person in the right foreground\nB. The woman in bright-red jacket\nC. The color of padded vest worn by the woman in the left foreground with purple sleeves\nD. The plaid coat worn by the woman on the far right", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 0.0, 2249.0, 988.0], [124.0, 408.0, 941.0, 1497.0], [1096.0, 465.0, 1882.0, 1496.0], [2034.0, 437.0, 2249.0, 1497.0], [893.0, 496.0, 1337.0, 1499.0]]"}
{"question_id": 347, "image": "image_000347.jpg", "question": "Considering their apparent sizes in the image, which is larger in really size: the small, dark, rectangular object embedded in the lower right white wall adjacent to the cobblestone path, or the small, square, dark window located high on the white cylindrical wall of the windmill to the right of its main blue door?", "options": "A. The small, square, dark window on the windmill is larger.\nB. They appear to be of equal size.\nC. The small, dark, rectangular object embedded in the lower right white wall is larger.\nD. It's impossible to compare their sizes due to perspective.", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[631.0, 388.0, 1410.0, 1387.0], [967.0, 1564.0, 1498.0, 2249.0]]"}
{"question_id": 348, "image": "image_000348.jpg", "question": "Guess from the image which car is the closest to the actual red bag on the road on the left\u5697", "options": "A. The orange truck\nB. The red mobile food truck\nC. The silver pickup truck\nD. The red pickup truck modified for public transportation", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[1184.0, 745.0, 2249.0, 1251.0], [624.0, 815.0, 998.0, 1094.0], [1035.0, 878.0, 1369.0, 1066.0], [285.0, 853.0, 351.0, 987.0], [30.0, 1062.0, 93.0, 1132.0]]"}
{"question_id": 349, "image": "image_000349.jpg", "question": "Which vehicle is closer in straight-line distance to the exact centre of the grassy roundabout?", "options": "A. The dark-blue hatchback that has just entered the circle from the upper-right road, immediately after the small red triangular island\nB. The white car entering the roundabout at the top left\nC. The white car at the top right road\nD. The long red bus negotiating the bottom-right exit", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[1235.0, 1158.0, 1336.0, 1219.0], [1530.0, 135.0, 1569.0, 171.0], [1226.0, 1204.0, 1269.0, 1229.0], [495.0, 139.0, 532.0, 178.0]]"}
{"question_id": 350, "image": "image_000350.jpg", "question": "Focus on the vertical metal lighting towers from left to right of the image are denoted 1,2,3,4 from left to right, which carries four stage spot-lights arranged in a column.  Comparing the straight-line gap between two  lighting tower, which of the following gaps looks the largest?", "options": "A. The gap between the 1 and 2\nB. The gap between the 4 and 3\nC. The gap between the 2 and 4\nD. The gap between the 1 and 3", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[96.0, 19.0, 251.0, 436.0], [524.0, 211.0, 569.0, 429.0], [738.0, 307.0, 782.0, 508.0], [1401.0, 367.0, 1456.0, 486.0]]"}
{"question_id": 351, "image": "image_000351.jpg", "question": "In the picture, the left side of the bus extends from the back of the car to the front of the car, a total of 10 hand straps, counting from 1 to 10, which is the actual distance and the little girl's head is the closest", "options": "A. 2\nB. 6\nC. 4\nD. 8", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[710.0, 902.0, 1153.0, 1499.0], [404.0, 165.0, 470.0, 466.0], [852.0, 349.0, 896.0, 528.0], [702.0, 283.0, 744.0, 507.0], [975.0, 416.0, 1004.0, 546.0]]"}
{"question_id": 352, "image": "image_000352.jpg", "question": "Look at the two office buildings on the right side of the street: Building  is the peach-colored rectangular block that forms the extreme right border of the image. The glass-covered building on the left can be seen in the shape of a glass tower. Which building is taller in the real world? ", "options": "A. Building  (peach-colored block) \nB. Building  (glass-covered building) \nC. Both appear exactly the same height \nD. It is impossible to judge from this angle ", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[872.0, 164.0, 2220.0, 718.0], [564.0, 606.0, 866.0, 817.0]]"}
{"question_id": 353, "image": "image_000353.jpg", "question": "Among the upright wooden posts that support the chain-link fence running along the right side of the dirt road, which post appears the tallest in the image? ", "options": "A. The very first post, the first post on the left of the rightmost isolated post\nB. The second post, located just beyond a blue plastic container leaning\nC. The third post, which are columns that coincide with the green house from the perspective of the camera\nD. They are the same height ", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[1609.0, 575.0, 1661.0, 957.0], [1957.0, 607.0, 2021.0, 967.0], [1451.0, 586.0, 1550.0, 923.0], [1439.0, 621.0, 1570.0, 717.0]]"}
{"question_id": 354, "image": "image_000354.jpg", "question": "Which object blue colour most closely matches the light, sky-blue tone of the plastic chair positioned next to the red taxi in the background?", "options": "A. The royal-blue front fairing of the orange-and-blue scooter parked in the bottom-left corner\nB. The turquoise-blue fabric canopy of the large umbrella shading several motorcycles on the right\nC. The top bright azure plastic crates stacked against the far-right wall beneath the umbrella pole\nD. The blue box under the umbrella on the right", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[85.0, 1631.0, 555.0, 2061.0], [817.0, 1330.0, 1305.0, 1518.0], [451.0, 798.0, 979.0, 918.0], [1177.0, 1800.0, 1322.0, 1959.0], [1378.0, 1403.0, 1476.0, 1571.0], [932.0, 808.0, 1005.0, 938.0]]"}
{"question_id": 355, "image": "image_000355.jpg", "question": "Which of the following small objects has the highest absolute position in real space", "options": "A. The square wooden sign with red letters staked in the grass just in front of the straw-covered fence\nB. The tiny dark rectangular vent set high on the right-hand barn steep shingled roof\nC. The slender metal tip of the church steeple\nD. The cross sign on the wooden door on the right", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[1393.0, 57.0, 2253.0, 799.0], [1846.0, 311.0, 2253.0, 1278.0], [1113.0, 532.0, 1201.0, 762.0], [1421.0, 1104.0, 1475.0, 1294.0]]"}
{"question_id": 356, "image": "image_000356.jpg", "question": "Considering the color of the letter \"E\" on a dark black background on the airplane's tail as a reference, which of these very small dark features in the image appears more similar in color:   the small, dark silhouette of the bird perched on the second power line from the top (above the rightmost propeller), or the small, dark shadow area directly beneath the tiny, metallic cap on the top of the brown, cylindrical fence post situated immediately to the right of the airplane's front landing gear wheel?", "options": "A. The color of commemorative plaque\nB. The color of the five-pointed star on an airplane\nC. The color of the nearest grass patch\nD. The color difference cannot be recognized", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[75.0, 1219.0, 2257.0, 1497.0], [454.0, 559.0, 2257.0, 1023.0], [1121.0, 983.0, 1328.0, 1228.0]]"}
{"question_id": 357, "image": "image_000357.jpg", "question": "Which person is closer to the right waterfall opening (the rectangular slot in the stone wall where water is gushing straight toward the camera)?", "options": "A. The person in a white T-shirt and black pants who is mid-stride on the grass directly in front of the large tree\nB. The person wearing a black coat with a white hat who is leaning on the metal railing right in front of the waterfall\nC. The woman dressed in black under the tree on the right\nD. The 3 people mentioned above are equally close to the waterfall", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[1399.0, 1111.0, 1503.0, 1324.0], [2058.0, 1252.0, 2108.0, 1364.0], [1363.0, 1267.0, 1402.0, 1355.0], [950.0, 1270.0, 967.0, 1341.0]]"}
{"question_id": 358, "image": "image_000358.jpg", "question": "Considering the yellow dashed line in the center of the road, how does the apparent length of the second complete yellow dash from the bottom edge of the image compare to the apparent length of the yellow dash located closest to the rear bumper of the white SUV?", "options": "A. The dash closest to the SUV's rear bumper appears longer.\nB. Both dashes appear to be of equal length.\nC. The second dash from the bottom edge appears significantly longer.\nD. The second dash from the bottom edge appears slightly shorter.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 8.0, 2249.0, 1499.0], [857.0, 512.0, 1556.0, 996.0]]"}
{"question_id": 359, "image": "image_000359.jpg", "question": "In the distant skyline, the actual height of the slender, blue-glass, cone-shaped skyscraper towering in the center of the frame, the narrow, dark gray chimney not far to its right, and the milky white building to the left of the frame. Which object in the photo is actually taller?", "options": "A. The smokestack appears tallest among the 3 buildings\nB. Themilky white buildin appears tallest among the 3 buildings\nC. The blue-glass skyscraper appearstallest among the 3 buildings\nD. All objects are not visible clearly enough to judge height.", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 0.0, 735.0, 1499.0], [1154.0, 539.0, 1285.0, 955.0], [1696.0, 594.0, 1728.0, 791.0]]"}
{"question_id": 360, "image": "image_000360.jpg", "question": "Which of the following straight-line distances appears the shortest in the scene?", "options": "A. From the curled tip of the left foreground elephant trunk to the pointed top of the stone sign that reads FROST\nB. From the back edge of the right-side reclining elephant ear to the nearest blue diamond-shaped opening in the fence behind it.\nC. From the front right foot of the left standing elephant (the foot closest to the viewer) to its own rear right foot.\nD. From the wing-like carved ornament on the right standing elephant head to the tip of that same elephant tusk.", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[278.0, 218.0, 1208.0, 992.0], [1329.0, 345.0, 2099.0, 923.0], [1247.0, 411.0, 1673.0, 967.0], [1068.0, 622.0, 1335.0, 809.0]]"}
{"question_id": 361, "image": "image_000361.jpg", "question": "On the facade of the large, light-grey warehouse with a dark grey sloping roof, observe the upper row of small, light-colored, circular/octagonal features.  How does the real world size of the leftmost visible feature in this row compare to the real world size of the rightmost visible feature in the same row (the one closest to the large, dark green tree on the right)?", "options": "A. Both features appear to be of approximately equal size.\nB. The rightmost feature appears significantly larger than the leftmost feature.\nC. The leftmost feature appears significantly larger than the rightmost feature.\nD. The leftmost feature appears slightly smaller than the rightmost feature.", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 338.0, 1258.0, 761.0]]"}
{"question_id": 362, "image": "image_000362.jpg", "question": " In the very top storey, compare the straight-line distance from the red flagpole tip to (i) the left-most point of the top circular balcony rail and (ii) the right-most point of the same rail.   Which distance looks longer in the photo?", "options": "A. Distance to the left-most point is longer\nB. Distance to the right-most point is longer\nC. The two distances look exactly equal\nD. The photograph gives too little information to judge", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[389.0, 193.0, 1004.0, 1999.0], [662.0, 30.0, 695.0, 215.0]]"}
{"question_id": 363, "image": "image_000363.jpg", "question": "Among the three tiny plush rabbits that sit inside the small burlap basket, whose head lies closest to the pink crocheted rim of the larger wicker basket behind them?", "options": "A. The rabbit wearing the blue-flower neck bow in the middle\nB. The rabbit wearing the red-and-white checkered apron and red bow on the left\nC. The rabbit at the back-right whose face is partly hidden and has only a red neck band\nD. All three rabbit heads are equally distant from the crocheted rim", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[451.0, 546.0, 1887.0, 1497.0], [297.0, 126.0, 1056.0, 1228.0], [938.0, 380.0, 1602.0, 1150.0], [203.0, 0.0, 1761.0, 393.0], [1354.0, 299.0, 1772.0, 951.0]]"}
{"question_id": 364, "image": "image_000364.jpg", "question": "Which object is closest in colour to the padded glove cuff on the right forearm of the front-right knight (he is swinging a pole toward the left)?", "options": "A. The round metal buckler fastened to the left elbow of the front-centre knight (he is wearing red and blue sleeves and facing the camera)\nB. The circular mask under the helmet of the front middle knight\nC. They appear exactly the same size\nD. Size cannot be judged from this view", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[743.0, 180.0, 1468.0, 1499.0], [1167.0, 604.0, 1476.0, 915.0]]"}
{"question_id": 365, "image": "image_000365.jpg", "question": "Compare the straight-line distance from the hub of the front wheel of a light-green bicycle (leaning against the sidewalk) to the different hanging lanterns below. Which distance is longer?", "options": "A. The white lantern on the left side of the second floor above the wooden door\nB. The white lantern on the second floor to the right above the wooden door\nC. The white lantern at the far right of the picture\nD. The one on the left of the red and white lanterns on the left of the picture", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[425.0, 1698.0, 726.0, 2042.0], [987.0, 1527.0, 1119.0, 1727.0], [466.0, 892.0, 525.0, 1001.0], [384.0, 997.0, 434.0, 1091.0], [239.0, 1477.0, 265.0, 1521.0]]"}
{"question_id": 366, "image": "image_000366.jpg", "question": "From the figure, we can guess which of the following objects has the largest actual diameter?", "options": "A. The closest truncated tree on the blackboard signal sign\nB. bowl next to lemur on the left\nC. The rightmost branch trunk from top to bottom\nD. Tie the tree trunk where the bowl is located", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 0.0, 1034.0, 1490.0], [1403.0, 1303.0, 1843.0, 1499.0], [1942.0, 300.0, 2088.0, 1499.0], [1628.0, 1153.0, 1758.0, 1334.0], [501.0, 712.0, 671.0, 831.0]]"}
{"question_id": 367, "image": "image_000367.jpg", "question": " Which of the following white, spherical lampeads' real size is the largest in the photograph? \n \n", "options": "A. The lamp closest to the viewer at the lower-right edge of the image\nB. The same\nC. The third lamp that rises directly in front of the white wall of the fortress, near the far end of the bridge \nD. The second lamp further down the same row, standing midway along the hand-rail", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[1922.0, 641.0, 1983.0, 1117.0], [1900.0, 813.0, 1932.0, 1071.0], [1894.0, 884.0, 1914.0, 1058.0]]"}
{"question_id": 368, "image": "image_000368.jpg", "question": "The figure of a person can be seen in the bottom right corner. Which of the several stools in the picture is the farthest away from this person?", "options": "A. bench on the right side of the square\nB. bench on the left side of the square\nC. The bench to the left of the arch\nD. The bench to the right of the arch", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[144.0, 1224.0, 256.0, 1377.0], [1619.0, 919.0, 1754.0, 1060.0], [312.0, 859.0, 453.0, 971.0], [965.0, 613.0, 1080.0, 711.0], [2194.0, 1091.0, 2249.0, 1172.0]]"}
{"question_id": 369, "image": "image_000369.jpg", "question": "What color is the rider of the horse farthest from the brown horse in the picture wearing?", "options": "A. White\nB. Yellow\nC. Gray\nD. Blue", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[663.0, 814.0, 1047.0, 1167.0], [495.0, 785.0, 825.0, 1035.0], [1134.0, 806.0, 1362.0, 971.0], [1379.0, 788.0, 1583.0, 1008.0], [833.0, 778.0, 968.0, 1042.0], [634.0, 736.0, 717.0, 945.0], [1475.0, 731.0, 1545.0, 927.0], [1225.0, 715.0, 1295.0, 889.0]]"}
{"question_id": 370, "image": "image_000370.jpg", "question": "Which of the following objects is the closest to the white car on the road on the right?", "options": "A. The bench on the right side of the frame is closest to the camera\nB. The orange house on the right\nC. A ship can be seen at the arch bridge entrance\nD. Cannot be distinguished from the information provided by the picture", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[1835.0, 638.0, 2106.0, 702.0], [2073.0, 868.0, 2145.0, 974.0], [2181.0, 768.0, 2216.0, 804.0], [1714.0, 762.0, 1745.0, 781.0]]"}
{"question_id": 371, "image": "image_000371.jpg", "question": "Of the backpacks you can see in the figure, which knapsack is estimated to have the largest actual maximum length (that is, when the knapsack is flat)?", "options": "A. The backpack of the man in the white coat closest to the camera\nB. A black backpack lying flat on the grass on the left\nC. On the right, a bag with a dark coat and white pants straddle the waist of a man\nD. The backpack standing upright beside the foot of the woman in the white hat on the left", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[967.0, 809.0, 1388.0, 1499.0], [333.0, 783.0, 508.0, 1416.0], [1321.0, 800.0, 1561.0, 1430.0], [215.0, 1248.0, 352.0, 1416.0], [1369.0, 903.0, 1584.0, 1108.0], [520.0, 1317.0, 757.0, 1401.0]]"}
{"question_id": 372, "image": "image_000372.jpg", "question": "Which object is closer to the tall grey street-lamp that has a o Smoking sign mounted on it?", "options": "A.A woman with a plastic bag in her hand\nB. The archway sign behind the lamp\nC. The red banner on the building on the right\nD. The actual distance cannot be analyzed from the picture", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[1067.0, 304.0, 1469.0, 744.0], [870.0, 290.0, 999.0, 977.0], [2096.0, 189.0, 2249.0, 400.0], [545.0, 688.0, 590.0, 812.0], [536.0, 763.0, 558.0, 806.0]]"}
{"question_id": 373, "image": "image_000373.jpg", "question": "Considering straight-line distance from the camera, which object is the farthest away(The camera is assumed to shoot at a symmetrical position in the middle of the current scene)?", "options": "A. The tip of the cone at the top of the golden building\nB. Safety light equipment in the bottom right corner\nC. The middle most biggest circular ceiling medallion on a red background\nD. The square horizontal column in the upper left corner of the picture from the top to the bottom view", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[355.0, 942.0, 1153.0, 2249.0], [50.0, 83.0, 314.0, 806.0], [666.0, 604.0, 838.0, 734.0], [1117.0, 2061.0, 1187.0, 2158.0]]"}
{"question_id": 374, "image": "image_000374.jpg", "question": "Which object is MOST similar in color to the sky-blue 'garuda' bag that is third from the top in the blue column of snack packets?", "options": "A. The color of the blue tape on the box with the letters 'qtela' written on it\nB. The color of the blue box in the middle of the screen\nC. The dominant color on the leftmost vertical row of boxes\nD. The box in the bottom-right corner is not visible in full view", "answer": "C", "category": "Reasoning/Comparison", "target_instances": "[[170.0, 540.0, 609.0, 1332.0], [836.0, 806.0, 1150.0, 1126.0], [1054.0, 1183.0, 1382.0, 1481.0], [2063.0, 1210.0, 2249.0, 1499.0], [438.0, 201.0, 538.0, 478.0]]"}
{"question_id": 375, "image": "image_000375.jpg", "question": "In the bottom-right quadrant, compare the location of the longest straight line from the tall cylindrical stone clock tower with a black dome (near the right edge)", "options": "A. A tower consisting of two columns on the left\nB. The white tall building on the right of the picture\nC. The roof of the red building in the bottom-left corner of the picture\nD. The top of the brown bell tower", "answer": "A", "category": "Reasoning/Comparison", "target_instances": "[[1185.0, 984.0, 1911.0, 1498.0], [0.0, 1100.0, 467.0, 1498.0], [1961.0, 650.0, 2085.0, 974.0], [1422.0, 738.0, 1473.0, 986.0], [203.0, 499.0, 226.0, 695.0]]"}
{"question_id": 376, "image": "image_000376.jpg", "question": "Would you please estimate the actual area of the object described below which is the largest?", "options": "A. The front of the blue locomotive on the left\nB. Cross section of the arch door far left (only half of the picture is calculated)\nC. The area of the third arched window from right to left\nD. The area of the fully exposed bench to the right of the locomotive", "answer": "B", "category": "Reasoning/Comparison", "target_instances": "[[0.0, 394.0, 1619.0, 1055.0], [2720.0, 301.0, 2979.0, 553.0], [0.0, 483.0, 249.0, 729.0], [1995.0, 898.0, 2419.0, 999.0]]"}
{"question_id": 377, "image": "image_000377.jpg", "question": "The actual straight-line distance of the bottom object is the furthest from the mouth of the sculptured horse above the pillar in the picture?", "options": "A. The head of the lion statue on the right\nB. the bottom of the rightmost street lamp\nC. The street lamp at the bottom left corner of the picture\nD. The top left corner of the reflective white billboard above the building on the left", "answer": "D", "category": "Reasoning/Comparison", "target_instances": "[[910.0, 225.0, 1345.0, 593.0], [1603.0, 1148.0, 1736.0, 1337.0], [2009.0, 784.0, 2163.0, 1298.0], [133.0, 986.0, 242.0, 1085.0], [46.0, 1195.0, 114.0, 1293.0]]"}
{"question_id": 378, "image": "image_000378.jpg", "question": "Considering the person wearing a dark coat with a fur-lined hood draped over their shoulder, standing alone in the middle of the street, what color are the pants of the person in front of him wearing a red coat and a gray hoodie?", "options": "A. Blue\nB. Black\nC. Yellow\nD. Red", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[838.0, 740.0, 929.0, 976.0], [667.0, 744.0, 705.0, 853.0]]"}
{"question_id": 379, "image": "image_000379.jpg", "question": "Which object is located directly to the right of the man wearing a black long-sleeve shirt, black pants, and a black cap who is standing on the left side of the street?", "options": "A. A white, medium-sized commercial truck parked near a gate \nB. A Scania P450 tanker truck with a red and white flag on top \nC. A healthy, medium to large coniferous tree near a road and a checkpoint \nD. A streetlight positioned on the side of a road, adjacent to a large concrete wall ", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[466.0, 342.0, 936.0, 1497.0], [1190.0, 435.0, 1687.0, 921.0]]"}
{"question_id": 380, "image": "image_000380.jpg", "question": " Which is the under wear of the person who is directly adjacent to the right side of the chestnut brown horse being ridden by a child, and is also behind the white horse?\n ", "options": "A. Skirt \nB. Short Pants\nC. Jeans\nD. Dress", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[534.0, 567.0, 914.0, 1174.0]]"}
{"question_id": 381, "image": "image_000381.jpg", "question": "What number is presented on the top of the white price tag in front of the figure with black bra on the left?", "options": "A. 7.99 \nB. 15 \nC. 23.99 \nD. 50%", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[378.0, 1091.0, 466.0, 1171.0]]"}
{"question_id": 382, "image": "image_000382.jpg", "question": " Which object is located immediately to the right of the black metal fence that separates the pedestrian area from the street?", "options": "A. The ornate street lamp with multiple lamp heads near the theater sign \nB. The golden-yellow bell tower with a domed top \nC. The white sedan driving in the right lane on the busy city street \nD. The small, blue spherical item near the metal railing", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[1528.0, 1271.0, 1623.0, 1351.0]]"}
{"question_id": 383, "image": "image_000383.jpg", "question": " Which object is located to the right of the large yellow tracked vehicle (drilling rig) and above the green and black striped fence?", "options": "A. The streetlight \nB. The blue corrugated metal sheeting \nC. The concrete barrier block \nD. The forest ", "answer": "A", "category": "Perception/Object Retrieval", "target_instances": "[[1957.0, 333.0, 2201.0, 1377.0]]"}
{"question_id": 384, "image": "image_000384.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. persons \nB. A sign with a logo \nC. Another building \nD. Tree", "answer": "D", "category": "Perception/OCR", "target_instances": "[[1275.0, 1066.0, 1352.0, 1148.0], [50.0, 50.0, 1373.0, 266.0]]"}
{"question_id": 385, "image": "image_000385.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Yellow \nB. Black \nC. White \nD. Green", "answer": "D", "category": "Perception/OCR", "target_instances": "[[1220.0, 291.0, 1540.0, 1497.0], [50.0, 50.0, 2139.890625, 230.0]]"}
{"question_id": 386, "image": "image_000386.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Adhesive shipping label \nB. California license plate \nC. Cardboard box with two upward arrows symbol \nD. Hinged metal latch ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[0.0, 30.0, 671.0, 1835.0], [50.0, 50.0, 1398.9375, 266.0]]"}
{"question_id": 387, "image": "image_000387.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The pale-yellow sheet titled AMBUSH! Mission Cartridge View Sleeve \nB. The white sheet headed AMBUSH! SQUAD RECORD with blank tables \nC. The light-gray sheet filled with numbered event columns \nD. The colorful hex-grid map page with the blue river and green terrain ", "answer": "D", "category": "Perception/OCR", "target_instances": "[[0.0, 194.0, 195.0, 1495.0], [50.0, 50.0, 2050.953125, 266.0]]"}
{"question_id": 388, "image": "image_000388.jpg", "question": "On the right side of the image, attached to a pole above the spectators, there is a circular red object with a horizontal white bar across its center. What is this object? ", "options": "A. Postbox  \nB. No-entry traffic sign  \nC. Carnival drum  \nD. Fire-alarm bell ", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[1844.0, 472.0, 1881.0, 514.0]]"}
{"question_id": 389, "image": "image_000389.jpg", "question": "Which object is positioned flush with the extreme left edge of the image, standing vertically and displaying white lettering on a black background? ", "options": "A. A decorative lamppost\nB. A banner with the word Oakley in white letters \nC. A banner with cyclist\nD. A Banner with yellow-and-black pattern in the center ", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[35.0, 745.0, 69.0, 917.0]]"}
{"question_id": 390, "image": "image_000390.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Circular blue stained-glass window \nB. Bronze door with relief carvings \nC. Hanging construction netting \nD. Stone gargoyle head ", "answer": "A", "category": "Perception/OCR", "target_instances": "[[646.0, 1787.0, 705.0, 1907.0], [50.0, 50.0, 1385.96875, 266.0]]"}
{"question_id": 391, "image": "image_000391.jpg", "question": "What object does a person use with his two hands in the left most side of the image that is closest to the camera?", "options": "A. Camera\nB. Phone\nC. Newspaper\nD. Bag", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[300.0, 1038.0, 490.0, 1294.0]]"}
{"question_id": 392, "image": "image_000392.jpg", "question": " What is the object being carried in the right hand of the man wearing a neon yellow shirt who is walking above the motorcycle? ", "options": "A. Smartphone  \nB. Red beverage bottle  \nC. Folded newspaper  \nD. Pair of sunglasses ", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[1008.0, 210.0, 1044.0, 255.0]]"}
{"question_id": 393, "image": "image_000393.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A concrete road barrier in the foreground \nB. The illuminated shop window across the street \nC. A vertical pole holding a square traffic sign \nD. The rectangular placard that reads FREE YOUR FACE.", "answer": "A", "category": "Perception/OCR", "target_instances": "[[0.0, 1035.0, 2247.0, 1497.0], [50.0, 50.0, 2158.96875, 266.0]]"}
{"question_id": 394, "image": "image_000394.jpg", "question": " Which object is *seated on the ground directly below the open red double doors* of the shrine entrance? ", "options": "A. A string of marigold flowers draped over a bell \nB. The seated stone statue of the elephant-headed deity (Ganesh) carved in dark stone \nC. The orange triangular prayer flag printed with a Hindu god image \nD. The medium-sized bronze bell that has a long chain and no stickers ", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[1986.0, 1301.0, 2179.0, 1498.0], [1216.0, 1281.0, 1341.0, 1482.0]]"}
{"question_id": 395, "image": "image_000395.jpg", "question": "What is attached to the top of the hat in the middle of the image?", "options": "A. Flag\nB. Sunglasses\nC. Flower\nD. Grass ring", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[1093.0, 1312.0, 1234.0, 1371.0]]"}
{"question_id": 396, "image": "image_000396.jpg", "question": " Which object is positioned directly under the child right foot, where a red strap is visible? ", "options": "A. Flat white sandal \nB. Gray stone paw of the statue \nC. Cluster of pink flowers in the bushes \nD. Small crumpled white tissue near a rock ", "answer": "A", "category": "Perception/Object Retrieval", "target_instances": "[[1041.0, 1460.0, 1306.0, 1567.0]]"}
{"question_id": 397, "image": "image_000397.jpg", "question": " Which object is positioned closest to the bottom edge, directly in the middle of the descending staircase? ", "options": "A. A black scooter facing uphill \nB. A silver compact car on the cobblestone street \nC. A white rack filled with postcard souvenirs \nD. A potted plant with pink flowers on the right wall ", "answer": "A", "category": "Perception/Object Retrieval", "target_instances": "[[928.0, 1209.0, 999.0, 1376.0]]"}
{"question_id": 398, "image": "image_000398.jpg", "question": "In the foreground, what is the man wearing bright pink shorts and blue sneakers holding in his right hand as he walks toward the camera? ", "options": "A. A folded newspaper \nB. A pink shopping bag \nC. A bottled drink \nD. A black umbrella ", "answer": "B", "category": "Perception/Object Retrieval", "target_instances": "[[561.0, 1094.0, 640.0, 1245.0]]"}
{"question_id": 399, "image": "image_000399.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A string of colorful pennant flags \nB. A red-and-white vertical cloth bearing a coat of arms \nC. A white poster with the words _\u4ea4_or Sale_ \nD. A checkered racing flag ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[335.0, 482.0, 1626.0, 1239.0], [50.0, 50.0, 1865.96875, 266.0]]"}
{"question_id": 400, "image": "image_000400.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. The brick tower with a steep conical roof on the far left edge \nB. A stacked red metro sign with white letters near the right edge \nC. The domed church tower rising above all other rooftops \nD. The rectangular tunnel opening beneath the bridge over the water ", "answer": "C", "category": "Perception/OCR", "target_instances": "[[813.0, 29.0, 1800.0, 1051.0], [50.0, 50.0, 2175.96875, 230.0]]"}
{"question_id": 401, "image": "image_000401.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A woven straw hat \nB. A teal cylindrical cup \nC. A glass soda bottle \nD. A laminated menu card ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[1769.0, 816.0, 1821.0, 1030.0], [50.0, 50.0, 1525.984375, 230.0]]"}
{"question_id": 402, "image": "image_000402.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. Bottled water \nB. Tempo tissues \nC. Bags of rice \nD. Boxes of face masks ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[2005.0, 533.0, 2152.0, 827.0], [2149.0, 677.0, 2249.0, 822.0], [50.0, 50.0, 2160.921875, 266.0]]"}
{"question_id": 403, "image": "image_000403.jpg", "question": "What color of the unbrella is the women in the right coner of house holding?", "options": "A. Pink\nB. Green\nC. Black\nD. Red", "answer": "C", "category": "Perception/Object Retrieval", "target_instances": "[[1364.0, 782.0, 1465.0, 1124.0]]"}
{"question_id": 404, "image": "image_000404.jpg", "question": "Recognize the question and options in the image and answer it.", "options": "A. A series of surfboards \nB. A set of white dining chairs \nC. A stack of folded deck loungers \nD. A collection of beach umbrellas ", "answer": "B", "category": "Perception/OCR", "target_instances": "[[332.0, 289.0, 1769.0, 1285.0], [50.0, 50.0, 2090.90625, 230.0]]"}
